{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "%matplotlib inline\n",
    "import sys\n",
    "# TODO: check with windows \n",
    "sys.path.insert(0, '../../db')\n",
    "sys.path.insert(0, '../../cam')\n",
    "import os\n",
    "import os.path\n",
    "import shutil\n",
    "\n",
    "from pylab import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pyAgrum as gum\n",
    "import pyAgrum.lib.notebook as gnb\n",
    "\n",
    "# from scipy.stats import norm\n",
    "\n",
    "import qi\n",
    "\n",
    "import pandas\n",
    "\n",
    "import math\n",
    "\n",
    "import glob\n",
    "\n",
    "import database as db\n",
    "\n",
    "import photo_handler\n",
    "    \n",
    "from datetime import datetime\n",
    "\n",
    "import csv\n",
    "\n",
    "import ast\n",
    "\n",
    "import time\n",
    "\n",
    "import threading\n",
    "\n",
    "import logging\n",
    "\n",
    "import random # for making random choices for the phrases\n",
    "\n",
    "import json\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "from multiprocessing.dummy import Pool as ThreadPool \n",
    "\n",
    "\"\"\"in the no-robot condition don't run this script\"\"\"\n",
    "class RecogniserBN:\n",
    "    \n",
    "    def __init__(self):\n",
    "        np.set_printoptions(threshold=np.nan)\n",
    "        self.useSpanish = False\n",
    "        self.isImageFromTablet = False\n",
    "        \n",
    "        self.recog_file = \"RecogniserBN.bif\"\n",
    "        self.csv_file = \"RecogniserBN.csv\"\n",
    "        self.initial_recognition_file = \"InitialRecognition.csv\"\n",
    "        self.analysis_file = \"AnalysisFolder/Analysis.json\"\n",
    "        self.db_file = \"db.csv\"\n",
    "        self.comparison_file = \"AnalysisFolder/Comparison.csv\"\n",
    "        self.node_names = [\"I\", \"F\", \"G\", \"A\", \"H\", \"T\"]\n",
    "        self.prob_threshold = 0.000001 # the probability below 0.000001 is regarded as 0.000001\n",
    "        self.init_min_threshold = 0.000001\n",
    "        self.max_threshold = 0.99\n",
    "        self.face_recognition_rate = 0.9\n",
    "        self.gender_recognition_rate = self.max_threshold\n",
    "        self.conf_threshold = 1 - self.max_threshold #the recognition confidence below 0.01 is regarded as 0.01 and all the probabilities are equal\n",
    "        # TODO: determine weights      \n",
    "        self.weights = [1.0, 0.8, 0.4, 0.2, 0.8] # [face_weight, gender_weight, age_weight, height_weight, time_weight]\n",
    "#         self.weights = [0.94, 0.03, 0.0, 0.09, 0.24]\n",
    "        self.conf_min_identity = 0.25 # minimum confidence of the identity recognition\n",
    "        \n",
    "        self.g_labels = [\"Female\", \"Male\"]\n",
    "        \n",
    "        self.unknown_var = \"0\"\n",
    "\n",
    "        self.age_min = 0\n",
    "        self.age_max = 75\n",
    "#         self.stddev_age = 2\n",
    "        z_age = self.normppf(self.max_threshold + (1-self.max_threshold)/2.0) \n",
    "        self.stddev_age = 0.5/z_age\n",
    "\n",
    "        self.height_min = 50 # TODO: LOOK AT THIS\n",
    "        self.height_max = 240 # TODO: LOOK AT THIS\n",
    "        self.stddev_height = 5 # TODO: LOOK AT THIS\n",
    "        self.height_curve_interval = 47 # TODO: change this if stddev_height changes\n",
    "        \n",
    "        self.period = 5 # time is checked every 5 minutes \n",
    "        self.stddev_time = 15/self.period # 15 minutes\n",
    "        self.time_min = 0\n",
    "        self.time_max = (7*24*60/self.period) -1 # 7(days)*24(hours)*60(minutes)/self.period ( = num_time_slots)\n",
    "        \n",
    "        # TODO: change this if stddev_time or period changes\n",
    "        if self.period == 1:\n",
    "            self.time_curve_interval = 135\n",
    "        else:\n",
    "            self.time_curve_interval = 135/self.period + 2\n",
    "\n",
    "# # # # #         self.l_labels = [\"Kitchen\", \"Office\"] \n",
    "\n",
    "        self.identity_est = \"\"\n",
    "        self.recog_results = []\n",
    "        self.isRegistered = True\n",
    "        self.isMemoryRobot = True\n",
    "        self.areParametersLearned = False\n",
    "        self.isBNLoaded = False\n",
    "        self.isDBinCSV = True\n",
    "        self.isUnknownCondition = False\n",
    "        self.nonweighted_evidence = []\n",
    "        self.ie = None\n",
    "        \n",
    "        self.isMultipleRecognitions = False\n",
    "        self.num_mult_recognitions = 3\n",
    "        self.mult_recognitions_list = []\n",
    "        self.ie_list = []\n",
    "        self.recog_results_list = []\n",
    "        self.analysis_data_list = []\n",
    "        \"\"\"\n",
    "        Nodes explained: \n",
    "\n",
    "        Identity: \"1\", \"2\", \"3\".., \"0\" (for \"unknown\")\n",
    "        Range variable because it is easier to change the number of states of the node as the database grows\n",
    "        \n",
    "        Face: \"1\"'s face, \"2\"'s face, \"3\"'s face.., \"0\" (for \"unknown\")    \n",
    "        See \"Identity\" variable explanation\n",
    "\n",
    "        Gender: Labelized variable. Female (0 in Naoqi), Male (1 in Naoqi) \n",
    "\n",
    "        Age: Range variable in [0, 75] (because Naoqi age detection is in the range of [0,75] )\n",
    "        !!!!!TONY: USE GAUSSIAN FOR P(AGE=a_i)!!!!!\n",
    "        !!!!!NOTE: should I decrease the range?!!!!!\n",
    "        !!!!!NOTE2: P(I=John|A=26) = this should be a Gaussian curve at mean 26, \n",
    "        since John can be 25 and the algorithm might be mistaken. I need to check this!!!!!\n",
    "        !!!!!NOTE3: should I use labelized variable instead? Like 0-10, 10-20, 20-30, etc. or smaller ranges? But in that case\n",
    "        P(A=26) = 40% will not be valid (should be higher confidence)!!!!!\n",
    "        \n",
    "        Height: Range variable [50, 240]\n",
    "        !!!!!TONY: USE GAUSSIAN FOR P(HEIGHT=h_i) (DON'T USE INTERVALS, USE REAL HEIGHT)!!!!!\n",
    "        \"80-90, 91-100, 101-110, 111-120, 121-130, 131-140, 141-150, 151-160, 161-170, 171-180, \n",
    "        181-190, 191-200, 201-210, 211-220, 221-230, 231-240\"\n",
    "            or\n",
    "        \"child, very short, short, normal, tall, very tall\"\n",
    "        !!!!!NOTE: height can be changed into a range variable, \n",
    "        but it is more reliable to categorise it in this way, I need to check this!!!!\n",
    "\n",
    "        Location: Range variable (can be changed to labelized variable). \n",
    "        Kitchen, bedroom, living room, office (the places can change depending on the experiment)\n",
    "        !!!!!NOTE_COLOMBIA: Not used as the location is the same!!!!!\n",
    "        \n",
    "        Time: Range variable\n",
    "        !!!!!TONY: USE GAUSSIAN PDF FOR P(TIME=t_i). t_i can be minutes!!!!! \n",
    "        !!!!!NOTE_COLOMBIA: Each patient has a certain timeslot and a day so this is possible to use!!!!!\n",
    "        !!!!!NOTE2:7(days)*24(hours)*60(minutes)/5(period) =  - I can change this to 7(days)*6(timeslots in day) = 42\n",
    "        Time slots: early morning (5.00.01 - 8.00.00), morning (8.00.01 - 12.00.00), afternoon (12.00.01 - 17.00.00), \n",
    "        evening (17.00.01 - 21.00.00), night (21.00.01 - 00.00.00), late night (00.00.01 - 5.00.00)!!!!!\n",
    "        \n",
    "        In RecogniserBN.csv: Field 'R' is used to identify the registering. If the person is registering for the first\n",
    "        time the value is 1, otherwise 0.\n",
    "        \"\"\"\n",
    "        \n",
    "    def connectToRobot(self, ip, port=9559, useSpanish = True, isImageFromTablet = True):\n",
    "        self.robot_ip = ip\n",
    "        self.robot_port = port\n",
    "        self.session = qi.Session()\n",
    "        try:\n",
    "            self.session.connect(\"tcp://\" + ip + \":\" + str(port))\n",
    "        except RuntimeError:\n",
    "            logging.debug(\"Can't connect to Naoqi at ip \\\"\" + ip + \"\\\" on port \" + str(port) +\".\\n\"\n",
    "               \"Please check your script arguments. Run with -h option for help.\")\n",
    "            sys.exit(1)\n",
    "        self.animatedSpeechProxy = self.session.service(\"ALAnimatedSpeech\")\n",
    "        self.tts = self.session.service(\"ALTextToSpeech\")\n",
    "        self.configuration = {\"bodyLanguageMode\":\"contextual\"}\n",
    "        self.useSpanish = useSpanish\n",
    "        self.recog_service = self.session.service(\"RecognitionService\")\n",
    "        self.isImageFromTablet = isImageFromTablet\n",
    "        self.recog_service.initSystem(self.useSpanish,self.isImageFromTablet,\"/home/nao/dev/images/nao_image.jpg\") # initialize the robot breathing, height offset, and language\n",
    "        \n",
    "    def setWeights(self, face_weight, gender_weight, age_weight, height_weight, time_weight):\n",
    "        self.weights = [face_weight, gender_weight, age_weight, height_weight, time_weight]\n",
    "    \n",
    "    def setFaceRecognitionRate(self, face_rate):\n",
    "        self.face_recognition_rate = face_rate\n",
    "        \n",
    "    def setGenderRecognitionRate(self, gender_rate):\n",
    "        self.gender_recognition_rate = gender_rate\n",
    "    \n",
    "    def updateFaceRecognitionRate(self):\n",
    "        self.face_recognition_rate = self.face_recognition_rate\n",
    "    \n",
    "#     def averageRecognitions(self, recog_list):\n",
    "#         face_result = []\n",
    "#         gender_result = []\n",
    "#         age_result = []\n",
    "#         height_result = []\n",
    "#         time_result = recog_list[0][4] # the recognitions will be within 5 minute period, so we can just assume that this will hold\n",
    "        \n",
    "#         for recog_counter in recog_list:\n",
    "#             # face\n",
    "#             if face_result:\n",
    "#                 cur_face_result = self.setFaceProbabilities(recog_counter[0], 1.0, isNormalisationOn = False)\n",
    "#                 face_result = [x + y for x, y in zip(face_result, cur_face_result)]\n",
    "#             else:\n",
    "#                 face_result = self.setFaceProbabilities(recog_counter[0], 1.0, isNormalisationOn = False)\n",
    "                \n",
    "#             # gender\n",
    "#             if gender_result:\n",
    "#                 cur_gender_result = self.setGenderProbabilities(recog_counter[1], 1.0)\n",
    "#                 gender_result = [x + y for x, y in zip(gender_result, cur_gender_result)]\n",
    "#             else:\n",
    "#                 gender_result = self.setGenderProbabilities(recog_counter[1], 1.0)\n",
    "            \n",
    "#             # age\n",
    "            \n",
    "#             # height\n",
    "                \n",
    "                \n",
    "#         face_result = self.normalise(face_result)\n",
    "#         face_recog = [1.0, []]\n",
    "        \n",
    "#         for i in range(0,len(face_result)):\n",
    "#             face_recog[1].append([self.i_labels[i], face_result[i]])\n",
    "        \n",
    "#         gender_result = self.normalise(gender_result)\n",
    "#         if gender_result[0] >= gender_result[1]:\n",
    "#             gender_recog = ['Female', gender_result[0]]\n",
    "#         else:\n",
    "#             gender_recog = ['Male', gender_result[1]]\n",
    "            \n",
    "        \n",
    "    def recognisePerson(self, num_recog = None):\n",
    "        if self.recog_results_from_file is None:\n",
    "            recog_results = [[0.6490000486373901, [['2', 0.8], ['1', 0.3]]],\n",
    "                              ['Female', 0.6], [28L, 0.5], [165.0, 0.0], ['18:31:14', '3', '06', 'June', '2017']]\n",
    "#             if self.isMultipleRecognitions:\n",
    "#                 recog_results = self.recog_service.recognisePerson(num_recog)\n",
    "#             else:\n",
    "#                 recog_results = self.recog_service.recognisePerson()\n",
    "        else:\n",
    "            if self.isMultipleRecognitions:\n",
    "                recog_results = self.recog_results_from_file[num_recog]\n",
    "            else:\n",
    "                recog_results = self.recog_results_from_file\n",
    "        return recog_results\n",
    "    \n",
    "    def learnPerson(self, isRegistered, p_id):\n",
    "#         if isRegistered:     \n",
    "#             if self.isMultipleRecognitions:\n",
    "#                 # multi-threading\n",
    "#                 for num_recog in range(0, self.num_mult_recognitions):\n",
    "#                     learn_face_success = self.recog_service.addPictureToPerson(p_id, num_recog)\n",
    "# #                     if learn_face_success:\n",
    "#                     # the image was analysed and the results were included in the network so it should be saved\n",
    "#                     self.saveImageToTablet(p_id, num_recog = num_recog)\n",
    "#                 # end of multi-threading\n",
    "#             else:\n",
    "#                 learn_face_success = self.recog_service.addPictureToPerson(p_id)\n",
    "# #                 if learn_face_success:\n",
    "#                 # the image was analysed and the results were included in the network so it should be saved\n",
    "#                 self.saveImageToTablet(p_id)\n",
    "#         else:\n",
    "#             if self.isMultipleRecognitions:\n",
    "#                 # multi-threading\n",
    "#                 for num_recog in range(0, self.num_mult_recognitions):\n",
    "#                     learn_face_success = self.recog_service.registerPerson(p_id, num_recog)\n",
    "#                     if num_recog == 0: # check the thread number\n",
    "#                         counter = 1\n",
    "#                         while not learn_face_success and counter < 3:\n",
    "#                             # TODO: take picture\n",
    "#                             learn_face_success = self.recog_service.registerPerson(p_id, num_recog) \n",
    "#                     self.saveImageToTablet(p_id, num_recog = num_recog)\n",
    "#                 # end of multi-threading\n",
    "#             else:\n",
    "#                 learn_face_success = self.recog_service.registerPerson(p_id)\n",
    "#                 counter = 1\n",
    "#                 while not learn_face_success and counter < 3:\n",
    "#                     # take another picture from tablet and send to robot\n",
    "#                     # TODO: try this!\n",
    "# #                     image_client = photo_handler.ImageClient()\n",
    "# #                     image_client.start()\n",
    "#                     learn_face_success = self.recog_service.registerPerson(p_id)\n",
    "                \n",
    "#                 self.saveImageToTablet(p_id)\n",
    "        bla = \"\"\n",
    "            \n",
    "            \n",
    "    def setFilePaths(self, recog_folder):\n",
    "        self.recog_file = recog_folder + self.recog_file \n",
    "        self.csv_file = recog_folder + self.csv_file\n",
    "        self.initial_recognition_file = recog_folder + self.initial_recognition_file\n",
    "        self.analysis_file = recog_folder + self.analysis_file\n",
    "        self.db_file = recog_folder + self.db_file\n",
    "        self.comparison_file = recog_folder + self.comparison_file\n",
    "    \n",
    "    def learnParameters(self, csv_file, initial_recognition_file):\n",
    "        # TODO: add location ast.literal_eval and append it to df when L (location) is used!\n",
    "\n",
    "        df=pandas.read_csv(csv_file, dtype={\"I\": object}, converters={\"F\": ast.literal_eval, \"G\": ast.literal_eval, \"A\": ast.literal_eval, \"H\": ast.literal_eval})\n",
    "        estimates_df = pandas.read_csv(initial_recognition_file, usecols=['F'], converters={\"F\": ast.literal_eval})\n",
    "        self.df_orig = df.copy()\n",
    "        self.df_I = set(df['I'].values.tolist())\n",
    "        accuracy_db = 2.0 # in recognition the confidence can be 1.0, hence I use 2.0 to differentiate from recognition\n",
    "        index_unknown = self.i_labels.index(self.unknown_var)\n",
    "        for counter in range(0, len(self.i_labels)):                     \n",
    "            if counter != index_unknown:\n",
    "#                 li_f = [math.pow(self.init_min_threshold,self.weights[0]) for x in range(0, len(self.i_labels))]\n",
    "#                 li_f[counter] = math.pow(1.0, self.weights[0])\n",
    "                li_f = [math.pow((1 - self.face_recognition_rate)/(len(self.i_labels)-1),self.weights[0]) for x in range(0, len(self.i_labels))]\n",
    "                li_f[counter] = math.pow(self.face_recognition_rate, self.weights[0])\n",
    "\n",
    "#                 li_f[counter] = math.pow(1 - ((len(self.i_labels)-1)*math.pow(self.init_min_threshold,self.weights[0])),self.weights[0])\n",
    "                li_f = self.normalise(li_f)\n",
    "\n",
    "                accuracy = 1.0\n",
    "                list_f = [[self.i_labels[x],li_f[x]] for x in range(0, len(self.i_labels))]\n",
    "                list_f = [accuracy, list_f]\n",
    "\n",
    "#                 li_g = [math.pow(self.init_min_threshold, self.weights[1]), math.pow(self.init_min_threshold, self.weights[1])]\n",
    "#                 if self.genders[counter] == self.g_labels[0]:\n",
    "#                     li_g[0] = math.pow(1-self.init_min_threshold, self.weights[1])\n",
    "#                 else:\n",
    "#                     li_g[1] = math.pow(1-self.init_min_threshold, self.weights[1])                \n",
    "        \n",
    "                li_g = [math.pow(1 - self.gender_recognition_rate, self.weights[1]), math.pow(1 - self.gender_recognition_rate, self.weights[1])]\n",
    "                if self.genders[counter] == self.g_labels[0]:\n",
    "                    li_g[0] = math.pow(self.gender_recognition_rate, self.weights[1])\n",
    "                else:\n",
    "                    li_g[1] = math.pow(self.gender_recognition_rate, self.weights[1])\n",
    "                li_g = self.normalise(li_g)\n",
    "                list_g = [[self.g_labels[x],li_g[x]] for x in range(0, len(self.g_labels))]\n",
    "            \n",
    "                # only add one entry for the first time of a person (the remaining times are added later in computeRangeCPTfromDF)\n",
    "                df = df.append(pandas.DataFrame.from_items([('I', [self.i_labels[counter]]), \n",
    "                                                                ('F', [list_f]), \n",
    "                                                                ('G', [list_g]),\n",
    "                                                                ('A', [[self.ages[counter], accuracy_db]]),\n",
    "                                                                ('H', [[self.heights[counter], accuracy_db]]),\n",
    "                                                                ('T', [self.findTimeSlot(self.times[counter][0])]), \n",
    "                                                                ('R', [0])]), ignore_index=True)\n",
    "#         print df\n",
    "        self.addUnknownLikelihood(self.r_bn)\n",
    "        self.updateUnknownLikelihood(df, estimates_df, self.r_bn)\n",
    "        for name_param in [\"I\",\"F\",\"G\"]:\n",
    "            self.computeLabelizedCPTfromDF(self.r_bn, df, name_param)\n",
    "        for name_param in [\"A\",\"H\",\"T\"]:\n",
    "            self.computeRangeCPTfromDF(self.r_bn, df, name_param)\n",
    "        \n",
    "        self.areParametersLearned = True\n",
    "\n",
    "        \n",
    "    def computeLabelizedCPTfromDF(self, bn, df, name_param): \n",
    "        \"\"\"Compute the CPT of variable \"name_param\" in the BN bn from the database df\"\"\"\n",
    "        id_v=bn.idFromName(name_param)        \n",
    "        index_unknown = self.i_labels.index(self.unknown_var)\n",
    "        \n",
    "        if name_param == \"I\":\n",
    "            bn.cpt(id_v)[:] = self.updatePriorI()\n",
    "        else:\n",
    "            group_v = df.loc[:,['I',name_param]].groupby('I')\n",
    "            for counter in range(0,len(self.i_labels)):\n",
    "                if counter != index_unknown:\n",
    "                    total_prob = []\n",
    "                    gr = group_v.get_group(self.i_labels[counter])\n",
    "                    for g_counter in range(0, len(gr)):\n",
    "                        l_val = gr.iloc[g_counter,1]\n",
    "                        prob_values = self.computeProbValues(name_param, l_val)\n",
    "\n",
    "                        if g_counter == 0:\n",
    "                            total_prob = prob_values[:]\n",
    "                        else:\n",
    "                            total_prob = [x + y for x, y in zip(total_prob, prob_values)]\n",
    "                \n",
    "                    total_prob = self.normalise(total_prob)    \n",
    "\n",
    "                    bn.cpt(id_v)[{'I':self.i_labels[counter]}] = total_prob[:]\n",
    "        \n",
    "    def computeRangeCPTfromDF(self, bn, df, name_param): \n",
    "        \"\"\"Compute the CPT of variable \"name_param\" in the BN bn from the database df (using soft evidence)\"\"\"\n",
    "        id_v=bn.idFromName(name_param)\n",
    "        index_unknown = self.i_labels.index(self.unknown_var)\n",
    "        \n",
    "        if name_param == \"A\":\n",
    "            min_value = self.age_min\n",
    "            max_value = self.age_max\n",
    "        elif name_param == \"H\": \n",
    "            min_value = self.height_min\n",
    "            max_value = self.height_max\n",
    "        elif name_param == \"T\":\n",
    "            min_value = self.time_min\n",
    "            max_value = self.time_max\n",
    "        # TODO: change age curve calculation such that it is faster (look at T or H calculations) \n",
    "        # (THINK ABOUT THE SIZE OF THE LIST -CURVE- WHICH COULD DETERMINE THE curve_interval)  \n",
    "            \n",
    "        group_v = df.loc[:,['I',name_param]].groupby('I')\n",
    "        for counter in range(0,len(self.i_labels)):\n",
    "            if counter != index_unknown:\n",
    "                gr = group_v.get_group(self.i_labels[counter])\n",
    "                curve_total_pdf = []\n",
    "                for g_counter in range(0, len(gr)):\n",
    "                    l_val = gr.iloc[g_counter,1]\n",
    "                    curve_pdf = self.computeProbValues(name_param, l_val)\n",
    "\n",
    "                    if g_counter == 0:\n",
    "                        curve_total_pdf = curve_pdf[:]\n",
    "                    else:\n",
    "                        curve_total_pdf = [x + y for x, y in zip(curve_total_pdf, curve_pdf)]\n",
    "\n",
    "                if name_param == \"T\":\n",
    "                    # add the remaining times in the database to the curve (when creating df, only the first time in the times of the person was added, so that\n",
    "                    # the data is not repeated for face, age, gender, and height (which would bias the network). This way, I only add the remaining times to the time curve only\n",
    "                    for t_counter in range(1, len(self.times[counter])): # start from self.times[counter][1] as 0 is used\n",
    "\n",
    "                        curve_pdf = self.computeProbValues(name_param, self.findTimeSlot(self.times[counter][t_counter]))\n",
    "\n",
    "                        curve_total_pdf = [x + y for x, y in zip(curve_total_pdf, curve_pdf)]\n",
    "                curve_total_pdf = self.normalise(curve_total_pdf)\n",
    "                bn.cpt(id_v)[{'I':self.i_labels[counter]}] = curve_total_pdf[:]\n",
    "    #             plt.plot(range(min_value, max_value + 1),curve_total_pdf, label=self.i_labels[counter])\n",
    "                        \n",
    "#         print name_param\n",
    "#         plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "#         plt.show()\n",
    "    \n",
    "    def computeProbValues(self, name_param, l_val):\n",
    "        if name_param == \"F\":\n",
    "            w_i = 0\n",
    "        elif name_param == \"G\":\n",
    "            w_i = 1\n",
    "        elif name_param == \"A\":\n",
    "            w_i = 2\n",
    "            stddev_v = self.stddev_age\n",
    "            min_value = self.age_min\n",
    "            max_value = self.age_max\n",
    "        elif name_param == \"H\":\n",
    "            w_i = 3\n",
    "            stddev_v = self.stddev_height\n",
    "            min_value = self.height_min\n",
    "            max_value = self.height_max\n",
    "            curve_interval = self.height_curve_interval\n",
    "            # TODO: change this if things change (this is for making the code more time-efficient, \n",
    "            # otherwise it takes very long to calculate pdf of each curve and add them up)\n",
    "            curve_pdf_base = [0.06309573444801932 for x in range(min_value, max_value + 1)]\n",
    "            curve_pdf_peak = [0.07268099908987054, 0.08701495407943342, 0.10334573211826904, 0.1217634209854823, \n",
    "                              0.14232027702569458, 0.1650221966252439, 0.18982070900788367, 0.21660599021810098, \n",
    "                              0.24520141868038245, 0.27536018101928744, 0.30676438883374674, 0.33902708124030684, \n",
    "                              0.37169736560460764, 0.4042687945841943, 0.4361908992560245, 0.46688360643780863, \n",
    "                              0.49575407629856555, 0.5222153182250288, 0.5457057929976087, 0.5657091007749367, \n",
    "                              0.58177279787487, 0.5935253879830573, 0.6006905979161397, 0.6030981722463664, \n",
    "                              0.6006905979161397, 0.5935253879830573, 0.58177279787487, 0.5657091007749367, \n",
    "                              0.5457057929976087, 0.5222153182250288, 0.49575407629856555, 0.46688360643780863, \n",
    "                              0.4361908992560245, 0.4042687945841943, 0.37169736560460764, 0.33902708124030684, \n",
    "                              0.30676438883374674, 0.27536018101928744, 0.24520141868038245, 0.21660599021810098, \n",
    "                              0.18982070900788367, 0.1650221966252439, 0.14232027702569458, 0.1217634209854823, \n",
    "                              0.10334573211826904, 0.08701495407943342, 0.07268099908987054]    \n",
    "        elif name_param == \"T\":\n",
    "            w_i = 4\n",
    "            stddev_v = self.stddev_time\n",
    "            min_value = self.time_min\n",
    "            max_value = self.time_max\n",
    "            curve_interval = self.time_curve_interval\n",
    "            # TODO: change this if things change (this is for making the code more time-efficient, \n",
    "            # otherwise it takes very long to calculate pdf of each curve and add them up)\n",
    "            curve_pdf_base = [1.5848931924611124e-05 for x in range(min_value, max_value + 1)]\n",
    "            curve_pdf_peak = [3.2797713065777e-05, 0.0001088922421767441, 0.00033078542438542475, 0.0009193731900581618, \n",
    "                              0.0023379399468789253, 0.005439649461045743, 0.011579892363179918, 0.02255455054751459, \n",
    "                              0.04019387502618488, 0.06553625561683843, 0.09776860472013102, 0.1334483646647943, \n",
    "                              0.16665683928175243, 0.19042723955981805, 0.19908156626677875, 0.19042723955981805, \n",
    "                              0.16665683928175243, 0.1334483646647943, 0.09776860472013102, 0.06553625561683843, \n",
    "                              0.04019387502618488, 0.02255455054751459, 0.011579892363179918, 0.005439649461045743, \n",
    "                              0.0023379399468789253, 0.0009193731900581618, 0.00033078542438542475, 0.0001088922421767441, \n",
    "                              3.2797713065777e-05]\n",
    "        \n",
    "        prob_values = []\n",
    "        prob = 1.0\n",
    "        if name_param == \"F\":\n",
    "            prob_values = self.setFaceProbabilities(l_val, self.weights[w_i])\n",
    "              \n",
    "        elif name_param == \"G\":\n",
    "            for gender_counter in range(0, len(self.g_labels)):\n",
    "                fr = l_val[gender_counter][1]\n",
    "                if fr > self.max_threshold:\n",
    "                    fr = self.max_threshold\n",
    "                elif fr < 1 - self.max_threshold:\n",
    "                    fr = 1 - self.max_threshold\n",
    "#                 if fr < self.prob_threshold:\n",
    "#                     fr = self.prob_threshold\n",
    "                prob_values.append(math.pow(fr,self.weights[w_i]))\n",
    "        else:\n",
    "            if name_param == \"T\":\n",
    "                mean_v = int(l_val)\n",
    "            else:                    \n",
    "                mean_v = int(l_val[0])\n",
    "                prob = float(l_val[1])\n",
    "                if name_param == \"A\":\n",
    "                    if prob > self.max_threshold and prob <= 1.0:\n",
    "                        prob = self.max_threshold\n",
    "\n",
    "                    if prob >= self.conf_threshold and prob <= self.max_threshold:\n",
    "#                         z= norm.ppf(prob + (1-prob)/2.0)                            \n",
    "                        z = self.normppf(prob + (1-prob)/2.0)                    \n",
    "                        stddev_v = 0.5/z\n",
    "                    else:\n",
    "                        stddev_v = self.stddev_age\n",
    "\n",
    "            if prob < self.conf_threshold:\n",
    "                # uniform distribution\n",
    "                j_pdf = 1.0/(max_value - min_value + 1)\n",
    "                prob_values = [j_pdf for x in range(min_value, max_value + 1)]\n",
    "            else:\n",
    "                # TODO: uncomment this when the weights are set (check and change the curve_pdf_peak and curve_pdf_base first)\n",
    "#                 if name_param == \"A\":\n",
    "#                     curve = norm(loc=mean_v,scale=stddev_v)  #Gaussian curve with mean at age of person and stddev of 2 years            \n",
    "                for j in range(min_value, max_value + 1):\n",
    "#                         j_pdf = curve.pdf(j)\n",
    "                    j_pdf = self.normpdf(j, mean_v, stddev_v)\n",
    "                    if j_pdf < self.prob_threshold:\n",
    "                        j_pdf = self.prob_threshold\n",
    "                    prob_values.append(math.pow(j_pdf,self.weights[w_i]))\n",
    "#                 else:\n",
    "#                     prob_values = curve_pdf_base[:]   \n",
    "#                     counter_tt = 0\n",
    "#                     while counter_tt <= (curve_interval -1)/2 and mean_v - counter_tt >= min_value:\n",
    "#                         prob_values[mean_v - counter_tt - min_value] = curve_pdf_peak[(curve_interval -1)/2 - counter_tt]\n",
    "#                         counter_tt += 1\n",
    "\n",
    "#                     counter_tt = 1\n",
    "#                     while counter_tt <= (curve_interval -1)/2 and mean_v + counter_tt <= max_value:\n",
    "#                         prob_values[mean_v + counter_tt - min_value] = curve_pdf_peak[(curve_interval -1)/2 + counter_tt]\n",
    "#                         counter_tt += 1\n",
    "        prob_values = self.normalise(prob_values)\n",
    "        return prob_values\n",
    "    \n",
    "    def loadBN(self, recog_file, csv_file, initial_recognition_file):\n",
    "        # load previous BN from file or create a new BN if the file doesn't exist\n",
    "        self.isBNLoaded = True\n",
    "        self.areParametersLearned = False\n",
    "        self.recog_file = recog_file\n",
    "        self.csv_file = csv_file\n",
    "        if self.isDBinCSV:\n",
    "            self.loadDBFromCSV(self.db_file)\n",
    "        else:\n",
    "            bla = \"\"\n",
    "#             self.loadDB()\n",
    "        self.num_recognitions = sum(1 for line in open(csv_file)) - 1\n",
    "\n",
    "        if os.path.isfile(recog_file):\n",
    "            self.r_bn = gum.loadBN(recog_file)\n",
    "            #         gnb.showBN(self.r_bn)\n",
    "            self.loadVariables()\n",
    "            self.setNumOccurrences(csv_file)\n",
    "        elif self.num_people > 1:\n",
    "            self.r_bn=gum.BayesNet('RecogniserBN')\n",
    "            self.addNodes()\n",
    "            self.addArcs()\n",
    "            self.setNumOccurrences(csv_file)\n",
    "            self.addCpts(csv_file, initial_recognition_file)\n",
    "            \n",
    "    def loadVariables(self):\n",
    "        self.I = self.r_bn.idFromName(\"I\")\n",
    "        self.F = self.r_bn.idFromName(\"F\")\n",
    "        self.G = self.r_bn.idFromName(\"G\")\n",
    "        self.A = self.r_bn.idFromName(\"A\")\n",
    "        self.H = self.r_bn.idFromName(\"H\")\n",
    "        self.T = self.r_bn.idFromName(\"T\")\n",
    "# #         self.L = self.r_bn.idFromName(\"L\")\n",
    "        \n",
    "    def updateProbabilities(self, p_id, ie):\n",
    "        \"\"\"Update P(I), P(F|I), P(G|I), P(A|I), P(H|I), P(T|I) in the network, before saving the network\"\"\"\n",
    "        if p_id == self.unknown_var:\n",
    "            iter_list = [self.node_names[1]]\n",
    "        else:\n",
    "            iter_list = self.node_names[1:]\n",
    "        \n",
    "        self.r_bn.cpt(self.I)[:] = self.updatePriorI()\n",
    "        occur = self.num_occurrences[self.i_labels.index(p_id)] + 1 # occurrence in the database is added to the number of occurrences\n",
    "        \n",
    "        for counter in range(0, len(iter_list)):\n",
    "            name_param = iter_list[counter]\n",
    "            id_v = self.r_bn.idFromName(name_param)\n",
    "\n",
    "            prev_prob_norm = self.r_bn.cpt(id_v)[{'I':p_id}][:]    \n",
    "            prev_prob = [i*occur for i in prev_prob_norm]\n",
    "            \n",
    "            l_val = self.nonweighted_evidence[counter]\n",
    "            prob_values = self.computeProbValues(name_param, l_val)\n",
    "            \n",
    "            total_prob = [x + y for x, y in zip(prev_prob, prob_values)]\n",
    "            norm_total_prob = self.normalise(total_prob)\n",
    "\n",
    "            self.r_bn.cpt(id_v)[{'I':p_id}] = norm_total_prob[:]\n",
    "            \n",
    "        self.num_occurrences[self.i_labels.index(p_id)] += 1\n",
    "    \n",
    "    def priorIOccurrences(self, p_id = None):\n",
    "        \"\"\"NOT USED!! Reason: when I use this P(I=i) = num_times_i_seen/num_recognitions,\n",
    "        the network is biased towards the people seen. So it is better to use equal values for P(I=i) = 1/len(database)\"\"\"\n",
    "        prob_values = self.num_occurrences[:]\n",
    "        if p_id is None:\n",
    "            if sum(self.num_occurrences) == 0:\n",
    "                prob_values = [1/len(self.i_labels) for i in range(0,len(self.i_labels))]\n",
    "            else:\n",
    "                for i_count in range(0, len(self.i_labels)):\n",
    "                    if self.num_occurrences[i_count] == 0:\n",
    "                        prob_values[i_count] = self.init_min_threshold\n",
    "            prob_values = [i/float(self.num_recognitions) for i in prob_values]\n",
    "        else:\n",
    "            index_name = self.i_labels.index(p_id)\n",
    "            if sum(self.num_occurrences) == 0:\n",
    "                prob_values = [self.init_min_threshold for i in range(0,len(self.i_labels))]\n",
    "                prob_values[index_name] = 1\n",
    "            else:            \n",
    "                for i_count in range(0, len(self.i_labels)):\n",
    "                    if i_count ==  index_name:\n",
    "                        prob_values[i_count] += 1\n",
    "                    elif self.num_occurrences[i_count] == 0:\n",
    "                        prob_values[i_count] = self.init_min_threshold\n",
    "\n",
    "            prob_values = [i/float(self.num_recognitions + 1) for i in prob_values]\n",
    "        prob_norm = self.normalise(prob_values)\n",
    "        return prob_norm\n",
    "        \n",
    "    def priorISequentialUpdating(self):\n",
    "        \"\"\"NOT USED!! Reason: Biases network towards people met before. \n",
    "        According to Sequential Bayesian updating, posterior of the previous calculation can be used as the prior\"\"\"\n",
    "        return self.ie.posterior(self.I)[:]        \n",
    "\n",
    "    def priorIEqualProbabilities(self):\n",
    "        return [1.0/len(self.i_labels) for i in range(0, len(self.i_labels))]\n",
    "        \n",
    "    def updatePriorI(self, p_id = None):\n",
    "#         updated_priors = self.priorISequentialUpdating()\n",
    "#         updated_priors = self.priorIOccurrences(p_id)\n",
    "        updated_priors = self.priorIEqualProbabilities()\n",
    "        return updated_priors\n",
    "    \n",
    "    def saveBN(self, recog_file, p_id, ie, num_recog = None):\n",
    "        # save BN before closing the system\n",
    "        self.recog_file = recog_file\n",
    "        self.updateProbabilities(p_id, ie)\n",
    "        if self.isMultipleRecognitions:\n",
    "            if num_recog == self.num_mult_recognitions - 1:\n",
    "                gum.saveBN(self.r_bn, recog_file)\n",
    "        else:\n",
    "            gum.saveBN(self.r_bn, recog_file)\n",
    "    \n",
    "    def updateData(self, person):\n",
    "#         person[0] = person[0].replace(\" \",\"_\")\n",
    "        self.i_labels.append(str(person[0]))\n",
    "        self.names.append(person[1])\n",
    "        self.genders.append(person[2])\n",
    "        self.ages.append(person[3])\n",
    "        self.heights.append(person[4])\n",
    "        times_patients = []\n",
    "        if self.isDBinCSV:\n",
    "            for tt in person[5]:\n",
    "                times_patients.append(tt[:2])\n",
    "        else:\n",
    "            for tt in person[5]:\n",
    "                times_patients.append([tt.time().strftime('%H:%M:%S'), tt.isoweekday()])\n",
    "        self.times.append(times_patients)\n",
    "        self.num_people += 1\n",
    "        \n",
    "    def loadDummyData(self):\n",
    "        self.i_labels = [\"1\",\"2\",\"3\"]\n",
    "        self.names = [\"Jane\",\"James\",\"John\"]\n",
    "        self.genders = [\"Female\",\"Male\",\"Male\"]\n",
    "        self.ages = [25,25,25]\n",
    "        self.heights = [168, 168, 168]\n",
    "        self.times =[[[\"11:00:00\",1]], [[\"11:00:00\",1]], [[\"11:00:00\",1], [\"12:00:00\",3]]]       \n",
    "        self.num_people = 3\n",
    "    \n",
    "    def addUnknown(self):\n",
    "        self.i_labels.insert(0, self.unknown_var)\n",
    "        self.names.insert(0, \"unknown\")\n",
    "        self.genders.insert(0, \"not-known\")\n",
    "        self.ages.insert(0, 35)\n",
    "        self.heights.insert(0, 165)\n",
    "        self.times.insert(0, [[\"00:00:00\",1]])\n",
    "     \n",
    "    def addUnknownLikelihood(self, bn):\n",
    "        # P(F|I)  : unknown is more likely to be unknown than anyone (however, this should change according to the result of inference)\n",
    "        # P(F=self.unknown_var|I=self.unknown_var) = 0.5, P(F!=self.unknown_var|I=self.unknown_var) = 0.5/(self.num_people - 1)\n",
    "        # self.num_people also includes self.unknown_var, whereas I need to divide it by the number of people in the database\n",
    "        counter = self.i_labels.index(self.unknown_var)\n",
    "#         li_f = [ math.pow(self.init_min_threshold,self.weights[0]) for x in range(0, len(self.i_labels))]\n",
    "#         li_f[counter] = math.pow(1.0, self.weights[0])\n",
    "#         li_f[counter] = math.pow(1 - ((len(self.i_labels)-1)*math.pow(self.init_min_threshold,self.weights[0])),self.weights[0])\n",
    "\n",
    "        # TODO: decide what to do with this\n",
    "#         li_f = [ 0.5/(self.num_people-1) for x in range(0, len(self.i_labels))]\n",
    "#         li_f[counter] = 0.5\n",
    "\n",
    "        li_f = [math.pow((1 - self.face_recognition_rate)/(len(self.i_labels)-1),self.weights[0]) for x in range(0, len(self.i_labels))]\n",
    "        li_f[counter] = math.pow(self.face_recognition_rate, self.weights[0])\n",
    "\n",
    "        bn.cpt(self.F)[{'I':self.unknown_var}] = self.normalise(li_f)\n",
    "        \n",
    "        # P(G|I) : Equally likely to be male or female\n",
    "        bn.cpt(self.G)[{'I':self.unknown_var}] = [0.5, 0.5]       \n",
    "        \n",
    "        # P(A|I) : Uniform distribution for unknown age\n",
    "        bn.cpt(self.A)[{'I':self.unknown_var}] = self.uniformDistribution(self.age_min, self.age_max)\n",
    "        \n",
    "        # P(H|I) : Uniform distribution for unknown height   \n",
    "        bn.cpt(self.H)[{'I':self.unknown_var}] = self.uniformDistribution(self.height_min, self.height_max)\n",
    "            \n",
    "        # P(T|I) : Uniform distribution for any time  \n",
    "        bn.cpt(self.T)[{'I':self.unknown_var}] = self.uniformDistribution(self.time_min, self.time_max)\n",
    "    \n",
    "    def updateUnknownLikelihood(self, df, estimates_df, bn):\n",
    "        \n",
    "        indices_unknown = list(np.where(df[\"R\"] == 1)[0])\n",
    "        if indices_unknown:\n",
    "            estimates_list = estimates_df['F'].values.tolist()\n",
    "\n",
    "            total_prob = bn.cpt(self.F)[{'I':self.unknown_var}][:]\n",
    "            for g_counter in indices_unknown:\n",
    "                l_val = estimates_list[g_counter]\n",
    "                prob_values = self.setFaceProbabilities(l_val, self.weights[0])\n",
    "                total_prob = [x + y for x, y in zip(total_prob, prob_values)]\n",
    "\n",
    "            total_prob = self.normalise(total_prob)    \n",
    "\n",
    "            bn.cpt(self.F)[{'I':self.unknown_var}] = total_prob[:]\n",
    "        \n",
    "    def loadDB(self):\n",
    "        self.i_labels = []\n",
    "        self.names = []\n",
    "        self.genders = []\n",
    "        self.ages = []\n",
    "        self.heights = []\n",
    "        self.times =[]       \n",
    "\n",
    "#         self.loadDummyData()\n",
    "        \n",
    "        db_handler = db.DbHandler()\n",
    "        p = db_handler.get_all_patients()\n",
    "        counter_p = 0\n",
    "        for a in p:\n",
    "#             name_person = str(a[\"name\"])\n",
    "#             name_person = name_person.replace(\" \",\"_\")\n",
    "#             self.i_labels.append(name_person)\n",
    "            self.i_labels.append(str(a[\"Id_number\"]))\n",
    "            self.names.append(str(a[\"name\"]))\n",
    "            self.genders.append(str(a[\"gender\"]))\n",
    "            self.ages.append(int(a[\"age\"]))\n",
    "            self.heights.append(float(a[\"height\"]))\n",
    "            times_patients = []\n",
    "            for tt in a[\"times\"]:\n",
    "                times_patients.append([tt.time().strftime('%H:%M:%S'), tt.isoweekday()])\n",
    "            self.times.append(times_patients)\n",
    "            counter_p = counter_p + 1\n",
    "        \n",
    "        self.addUnknown()\n",
    "        \n",
    "        self.num_people = len(self.i_labels)\n",
    "        \n",
    "#         self.printDB()\n",
    "\n",
    "    def loadDBFromCSV(self, csv_file):\n",
    "        db_df = pandas.read_csv(csv_file, dtype={\"id\": object}, converters={\"times\": ast.literal_eval})\n",
    "#         self.i_labels = db_df['name'].values.tolist()\n",
    "        self.i_labels = db_df['id'].values.tolist()\n",
    "        self.names = db_df['name'].values.tolist()\n",
    "        self.genders = db_df['gender'].values.tolist()\n",
    "        self.ages = db_df['age'].values.tolist()\n",
    "        self.heights = db_df['height'].values.tolist()\n",
    "        self.times = [] \n",
    "        ti = db_df['times'].values.tolist()\n",
    "        for t in ti:\n",
    "            times_patients = []\n",
    "            for tt in t:\n",
    "                times_patients.append(tt[:2])\n",
    "            self.times.append(times_patients)\n",
    "        \n",
    "        self.addUnknown()\n",
    "        \n",
    "        self.num_people = len(self.i_labels)\n",
    "        \n",
    "\n",
    "    def addNodes(self):  \n",
    "        \n",
    "        # Identity node\n",
    "        self.identity = gum.LabelizedVariable(\"I\",\"Identity\",0)\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            self.identity.addLabel(self.i_labels[counter])       \n",
    "        self.I = self.r_bn.add(self.identity)\n",
    "        \n",
    "        # Face node\n",
    "        self.face = gum.LabelizedVariable(\"F\",\"Face\",0)\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            self.face.addLabel(self.i_labels[counter]) \n",
    "        self.F = self.r_bn.add(self.face)       \n",
    "\n",
    "        # Gender node\n",
    "        self.gender = gum.LabelizedVariable(\"G\",\"Gender\",0)\n",
    "        for counter in range(0, len(self.g_labels)):\n",
    "            self.gender.addLabel(self.g_labels[counter])\n",
    "        self.G = self.r_bn.add(self.gender)\n",
    "        \n",
    "        # Age node\n",
    "        self.age = gum.RangeVariable(\"A\",\"Age\",self.age_min,self.age_max)\n",
    "        self.A = self.r_bn.add(self.age)      \n",
    "        \n",
    "        # Height node\n",
    "        self.height = gum.RangeVariable(\"H\",\"Height\",self.height_min,self.height_max)\n",
    "        self.H = self.r_bn.add(self.height)\n",
    "        \n",
    "        # Time node\n",
    "        self.time_of_day = gum.RangeVariable(\"T\",\"Time\",self.time_min,self.time_max)\n",
    "        self.T = self.r_bn.add(self.time_of_day)\n",
    "        \n",
    "#         gnb.showBN(self.r_bn)\n",
    "        \n",
    "# # # # #         # Location node\n",
    "# # # # #         self.location = gum.LabelizedVariable(\"L\",\"Location\",0)\n",
    "# # # # #         for counter in range(0, len(self.l_labels)):\n",
    "# # # # #             self.location.addLabel(self.l_labels[counter])\n",
    "# # # # #         self.L = self.r_bn.add(self.location)\n",
    "        \n",
    "        \n",
    "    def addArcs(self):\n",
    "        self.r_bn.addArc(self.I,self.F)\n",
    "        self.r_bn.addArc(self.I,self.G)\n",
    "        self.r_bn.addArc(self.I,self.A)\n",
    "        self.r_bn.addArc(self.I,self.H)\n",
    "        self.r_bn.addArc(self.I,self.T)\n",
    "# #  #       self.r_bn.addArc(self.T,self.L)\n",
    "# #  #       self.r_bn.addArc(self.I,self.L)\n",
    "    \n",
    "    def findTimeSlot(self, p_time):\n",
    "        tp = p_time[0].split(\":\") \n",
    "        time_slot = (int(p_time[1])-1)*24*60/self.period + int(tp[0])*60/self.period + int(tp[1])/self.period\n",
    "        return time_slot\n",
    "    \n",
    "    def addCpts(self, csv_file, initial_recognition_file):\n",
    "        start_time = time.time()\n",
    "        if self.num_recognitions > 0:\n",
    "            self.learnParameters(csv_file, initial_recognition_file)\n",
    "        else:\n",
    "            # P(I)\n",
    "            self.r_bn.cpt(self.I).fillWith(1).normalize()\n",
    "            index_unknown = self.i_labels.index(self.unknown_var)\n",
    "            # P(F|I), P(G|I), P(A|I), P(H|I), P(T|I)\n",
    "            for counter in range(0, len(self.i_labels)):\n",
    "                if counter == index_unknown:\n",
    "                    self.addUnknownLikelihood(self.r_bn)\n",
    "                else:\n",
    "                    self.addLikelihoods(counter)\n",
    "        print \"time passed for learning: \" + str(time.time() - start_time)\n",
    "\n",
    "    def addLikelihoods(self, counter):\n",
    "        \"\"\"Start with equal probabilities for identities, i.e. P(I=i) = 1/num_people_db. For P(F=j|I=i) = self.prob_threshold for j!=i\n",
    "        and 1-(num_people_db-1)*self.prob_threshold) if j=i\"\"\"\n",
    "        \n",
    "        # P(F|I)  \n",
    "\n",
    "#         li_f = [ math.pow(self.init_min_threshold,self.weights[0]) for x in range(0, len(self.i_labels))]\n",
    "#         li_f[counter] = math.pow(1.0, self.weights[0])\n",
    "\n",
    "#         li_f[counter] = math.pow(1 - ((len(self.i_labels)-1)*math.pow(self.init_min_threshold,self.weights[0])),self.weights[0])\n",
    "        \n",
    "        li_f = [math.pow((1 - self.face_recognition_rate)/(len(self.i_labels)-1),self.weights[0]) for x in range(0, len(self.i_labels))]\n",
    "        li_f[counter] = math.pow(self.face_recognition_rate, self.weights[0])\n",
    "        \n",
    "        li_f = self.normalise(li_f)\n",
    "        # what it does: self.r_bn.cpt(self.I)[{'F':0}]=1 SAME THING AS: self.r_bn.cpt(self.I)[{'F':self.unknown_var}]=[0.5,0.5]\n",
    "        self.r_bn.cpt(self.F)[{'I':self.i_labels[counter]}] = li_f[:]\n",
    "\n",
    "        # P(G|I)  \n",
    "#         li_g = [math.pow(self.init_min_threshold, self.weights[1]), math.pow(self.init_min_threshold, self.weights[1])]\n",
    "#         if self.genders[counter] == self.g_labels[0]:\n",
    "#             li_g[0] = math.pow(1-self.init_min_threshold, self.weights[1])\n",
    "#         else:\n",
    "#             li_g[1] = math.pow(1-self.init_min_threshold, self.weights[1])\n",
    "\n",
    "        li_g = [math.pow(1 - self.gender_recognition_rate, self.weights[1]), math.pow(1 - self.gender_recognition_rate, self.weights[1])]\n",
    "        if self.genders[counter] == self.g_labels[0]:\n",
    "            li_g[0] = math.pow(self.gender_recognition_rate, self.weights[1])\n",
    "        else:\n",
    "            li_g[1] = math.pow(self.gender_recognition_rate, self.weights[1])\n",
    "        li_g = self.normalise(li_g)\n",
    "        self.r_bn.cpt(self.G)[{'I':self.i_labels[counter]}] = li_g[:]        \n",
    "        \n",
    "        # P(A|I)      \n",
    "        age_curve_pdf = self.getCurve(mean = self.ages[counter], stddev = self.stddev_age, min_value = self.age_min, max_value = self.age_max, weight = self.weights[2])\n",
    "        self.r_bn.cpt(self.A)[{'I':self.i_labels[counter]}] = age_curve_pdf[:]\n",
    "        \n",
    "        # P(H|I)        \n",
    "        height_curve_pdf = self.getCurve(mean = self.heights[counter], stddev = self.stddev_height, min_value = self.height_min, max_value = self.height_max, weight = self.weights[3])\n",
    "        self.r_bn.cpt(self.H)[{'I':self.i_labels[counter]}] = height_curve_pdf[:]\n",
    "            \n",
    "        # P(T|I)\n",
    "        time_curve_total_pdf = []\n",
    "        for t_counter in range(0, len(self.times[counter])):\n",
    "            time_curve_pdf = self.getCurve(mean = self.findTimeSlot(self.times[counter][t_counter]), stddev = self.stddev_time, min_value = self.time_min, max_value = self.time_max, weight = self.weights[4])\n",
    "            if t_counter == 0:\n",
    "                time_curve_total_pdf = time_curve_pdf[:]\n",
    "            else:\n",
    "                time_curve_total_pdf = [x + y for x, y in zip(time_curve_total_pdf, time_curve_pdf)]            \n",
    "        time_curve_total_pdf = self.normalise(time_curve_total_pdf)\n",
    "        self.r_bn.cpt(self.T)[{'I':self.i_labels[counter]}] = time_curve_total_pdf[:]\n",
    "    \n",
    "    def setFaceProbabilities(self, face_values, weight, isNormalisationOn = True):\n",
    "        accuracy_face = face_values[0]\n",
    "        face_similarities = []\n",
    "        if len(face_values[1]) > 0:\n",
    "            face_similarities = face_values[1][:]\n",
    "            \n",
    "        if len(face_similarities) == 0:\n",
    "            face_similarities.append([self.unknown_var, 1.0])\n",
    "        elif not (self.unknown_var in (x[0] for x in face_similarities)):\n",
    "            max_similarity = max(face_similarities, key=lambda x: x[1])[1] # maximum similarity score in the face recognition\n",
    "            face_similarities.append([self.unknown_var, 1.0 - max_similarity]) # the similarity score of unknown is 1-max_similarity\n",
    "        \n",
    "        r_results_names = []\n",
    "        for counter in range(0, len(face_similarities)):\n",
    "            r_results_names.append(face_similarities[counter][0])\n",
    "        \n",
    "        r_results_index = []\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            if self.i_labels[counter] in r_results_names:\n",
    "                r_results_index.append(r_results_names.index(self.i_labels[counter]))\n",
    "            else:\n",
    "                # if the person in database is not in face recognition database yet (did not have his/her first session yet)\n",
    "                r_results_index.append(-1)\n",
    "\n",
    "        face_result = []\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            # values are normalised when using this method \n",
    "            if r_results_index[counter] == -1:\n",
    "                fr = self.prob_threshold\n",
    "            else:\n",
    "                fr = face_similarities[r_results_index[counter]][1]\n",
    "                if fr < self.prob_threshold:\n",
    "                    fr = self.prob_threshold\n",
    "#             face_result.append(math.pow(fr,accuracy_face))\n",
    "            accur = math.pow(fr,accuracy_face)\n",
    "            face_result.append(math.pow(accur, weight))\n",
    "        if isNormalisationOn:\n",
    "            face_result = self.normalise(face_result)\n",
    "        return face_result\n",
    "    \n",
    "    def setGenderProbabilities(self, gender_values, weight):\n",
    "        gr = gender_values[1]\n",
    "        \n",
    "        # TODO: think about this!\n",
    "        if gr > self.max_threshold:\n",
    "            gr = self.max_threshold\n",
    "#         if gr >= 1.0 - self.prob_threshold:\n",
    "#             gr = 1 - self.prob_threshold    \n",
    "        gr_comp = 1 - gr\n",
    "        \n",
    "        gr_comp = math.pow(gr_comp, weight)\n",
    "        gr = math.pow(gr, weight)\n",
    "        sum_gr = gr + gr_comp\n",
    "        if gender_values[0] == self.g_labels[0]:\n",
    "            gender_result = [gr/sum_gr, gr_comp/sum_gr] \n",
    "        else:\n",
    "            gender_result = [gr_comp/sum_gr, gr/sum_gr]\n",
    "        return gender_result\n",
    "\n",
    "    def getNonweightedEvidenceResult(self):\n",
    "        # P(e|F)\n",
    "        face_result = self.setFaceProbabilities(self.recog_results[0], 1.0)\n",
    "        \n",
    "        # P(e|G)\n",
    "        gender_result = self.setGenderProbabilities(self.recog_results[1], 1.0)\n",
    "\n",
    "        # P(e|A)\n",
    "        age_result = self.getCurve(conf = self.recog_results[2][1], mean = self.recog_results[2][0], min_value = self.age_min, max_value = self.age_max, weight = 1.0)\n",
    "\n",
    "        # P(e|H)\n",
    "        height_result = self.getCurve(conf = self.recog_results[3][1], mean = self.recog_results[3][0], stddev = self.stddev_height, min_value = self.height_min, max_value = self.height_max, weight = 1.0)\n",
    "        \n",
    "        # P(e|T)   \n",
    "        # todo: check time curve! \n",
    "        time_result = self.getCurve(mean = self.findTimeSlot(self.recog_results[4]), stddev = self.stddev_time, min_value = self.time_min, max_value = self.time_max, weight = 1.0)\n",
    "    \n",
    "        return [face_result, gender_result, age_result, height_result, time_result] \n",
    "    \n",
    "    def setEvidence(self, recog_results, param_weights = None):\n",
    "        \"\"\"Call this function for self.num_people >=2 (when BN is created)\"\"\"\n",
    "        # self.printPriors()\n",
    "        \n",
    "        if param_weights is None:\n",
    "            param_weights = self.weights\n",
    "            \n",
    "        # P(e|F)\n",
    "        face_result = self.setFaceProbabilities(recog_results[0], param_weights[0])\n",
    "        \n",
    "        # P(e|G)\n",
    "        gender_result = self.setGenderProbabilities(recog_results[1], param_weights[1])\n",
    "\n",
    "        # P(e|A)\n",
    "        age_result = self.getCurve(conf = recog_results[2][1], mean = recog_results[2][0], min_value = self.age_min, max_value = self.age_max, weight = param_weights[2])\n",
    "\n",
    "        # P(e|H)\n",
    "        height_result = self.getCurve(conf = recog_results[3][1], mean = recog_results[3][0], stddev = self.stddev_height, min_value = self.height_min, max_value = self.height_max, weight = param_weights[3])\n",
    "        \n",
    "        # P(e|T)   \n",
    "        # todo: check time curve! \n",
    "        time_result = self.getCurve(mean = self.findTimeSlot(recog_results[4]), stddev = self.stddev_time, min_value = self.time_min, max_value = self.time_max, weight = param_weights[4])\n",
    "        \n",
    "        \n",
    "#         self.printEvidence(face_result, gender_result, age_result, height_result, time_result)\n",
    "        \n",
    "#         gnb.showInference(self.r_bn,evs={\"F\":face_result, \"G\":gender_result, \"A\":age_result, \"H\":height_result, \"T\":time_result})\n",
    "        \n",
    "        ie = gum.LazyPropagation(self.r_bn)\n",
    "        ie.setEvidence({\"F\":face_result, \"G\":gender_result, \"A\":age_result, \"H\":height_result, \"T\":time_result})\n",
    "        ie.makeInference()\n",
    "        \n",
    "#         self.printInference(ie)\n",
    "        print \"ie.posterior(self.F):\"\n",
    "        print ie.posterior(self.F)\n",
    "        print \"ie.posterior(self.I):\"\n",
    "        print ie.posterior(self.I)\n",
    "        return ie\n",
    "    \n",
    "    def getPosteriorIUsingCalculatedEvidence(self, bn, evidence):\n",
    "        ie = gum.LazyPropagation(bn)\n",
    "        ie.setEvidence({\"F\":evidence[0], \"G\":evidence[1], \"A\":evidence[2], \"H\":evidence[3], \"T\":evidence[4]})\n",
    "        ie.makeInference()\n",
    "        post_I = ie.posterior(self.I)[:]\n",
    "#         i_post = np.array(post_I)\n",
    "#         i_max_cpt = np.max(ie.posterior(self.I)[:])\n",
    "#         identity_est = self.i_labels[np.argmax(ie.posterior(self.I)[:])]\n",
    "#         if np.isclose(i_post, i_max_cpt).all() or i_max_cpt < self.conf_min_identity or len(i_post[i_post>=i_max_cpt]) > 1:      \n",
    "#             i_post[0] += 1.0\n",
    "#             post_I = self.normalise(i_post)\n",
    "        return post_I\n",
    "    \n",
    "    def getEstimatedProbabilities(self):\n",
    "        \"\"\"If the results is unknown because of an unknown condition (see recognise function), increase the probability of unknown and normalise\"\"\"\n",
    "        if self.num_people > 1:\n",
    "            post_I = self.ie.posterior(self.I)[:]\n",
    "    #         if self.isUnknownCondition:\n",
    "    #             post_I[0] += 1.0\n",
    "    #             post_I = self.normalise(post_I)\n",
    "        else:\n",
    "            post_I = [1.0] # unknown\n",
    "        return post_I\n",
    "    \n",
    "    def fillNonweightedEvidence(self, recog_results):\n",
    "        \n",
    "        # SOFT EVIDENCE:\n",
    "        face_est = recog_results[0][:]\n",
    "        \n",
    "        gender_val = recog_results[1][:]\n",
    "        if gender_val[0] == self.g_labels[0]:\n",
    "            gender_est = [[self.g_labels[0], gender_val[1]],[self.g_labels[1], 1- gender_val[1]]]\n",
    "        else:\n",
    "            gender_est = [[self.g_labels[0], 1- gender_val[1]],[self.g_labels[1], gender_val[1]]]\n",
    "        age_est = recog_results[2][:]\n",
    "        height_est = recog_results[3][:]\n",
    "        time_cur= recog_results[4][:]\n",
    "        time_est = self.findTimeSlot(time_cur) #hard evidence for time\n",
    "        \n",
    "        return [face_est, gender_est, age_est, height_est, time_est]\n",
    "        \n",
    "        # HARD EVIDENCE: \n",
    "#         face_est = recog_results[0][1][0][0]\n",
    "#         gender_est = recog_results[1][0]\n",
    "#         age_est = recog_results[2][0]\n",
    "#         height_est = recog_results[3][0]\n",
    "#         time_cur= recog_results[4]\n",
    "#         time_est = self.findTimeSlot(time_cur)\n",
    "        \n",
    "    def saveCSV(self, csv_file, identity_real):\n",
    "        self.csv_file = csv_file\n",
    "        r = 0 # is not registering\n",
    "        if not self.isRegistered:\n",
    "            r = 1 # is registering\n",
    "        \n",
    "        df = pandas.DataFrame.from_items([('I', [identity_real]), \n",
    "                                          ('F', [self.nonweighted_evidence[0]]), \n",
    "                                          ('G', [self.nonweighted_evidence[1]]),\n",
    "                                          ('A', [self.nonweighted_evidence[2]]),\n",
    "                                          ('H', [self.nonweighted_evidence[3]]),\n",
    "                                          ('T', [self.nonweighted_evidence[4]]),\n",
    "                                          ('R', [r])])\n",
    "        with open(csv_file, 'a') as fd:\n",
    "            df.to_csv(fd, index=False, header=False)\n",
    "    \n",
    "    def saveEstimatedResultCSV(self, initial_recognition_file, recog_results, identity_est):\n",
    "        self.initial_recognition_file = initial_recognition_file\n",
    "        \n",
    "        gender_val = recog_results[1][:]\n",
    "        if gender_val[0] == self.g_labels[0]:\n",
    "            gender_est = [[self.g_labels[0], gender_val[1]],[self.g_labels[1], 1- gender_val[1]]]\n",
    "        else:\n",
    "            gender_est = [[self.g_labels[0], 1- gender_val[1]],[self.g_labels[1], gender_val[1]]]\n",
    "            \n",
    "        time_cur= recog_results[4][:]\n",
    "        time_est = self.findTimeSlot(time_cur) #hard evidence for time\n",
    "        \n",
    "        df = pandas.DataFrame.from_items([('I_est', [identity_est]), \n",
    "                                          ('F', [recog_results[0][:]]), \n",
    "                                          ('G', [gender_est]),\n",
    "                                          ('A', [recog_results[2][:]]),\n",
    "                                          ('H', [recog_results[3][:]]),\n",
    "                                          ('T', [time_est])])\n",
    "        with open(initial_recognition_file, 'a') as fd:\n",
    "            df.to_csv(fd, index=False, header=False)\n",
    "            \n",
    "    def saveComparisonCSV(self, comparison_file, identity_real, identity_est, posterior_average, calc_time):\n",
    "        self.comparison_file = comparison_file\n",
    "        r = 0 # is not registering\n",
    "        if not self.isRegistered:\n",
    "            r = 1 # is registering\n",
    "        \n",
    "        df = pandas.DataFrame.from_items([('I_real', [identity_real]), \n",
    "                                          ('I_est', [identity_est]), \n",
    "                                          ('I_prob', [posterior_average]),\n",
    "                                          ('Calc_time', [calc_time]),\n",
    "                                          ('R', [r])])\n",
    "        with open(comparison_file, 'a') as fd:\n",
    "            df.to_csv(fd, index=False, header=False)\n",
    "            \n",
    "    def saveDBToCSV(self, db_file, person):\n",
    "        df = pandas.DataFrame.from_items([('id', [person[0]]),\n",
    "                                          ('name', [person[1]]), \n",
    "                                          ('gender', [person[2]]), \n",
    "                                          ('age', [person[3]]),\n",
    "                                          ('height', [person[4]]),\n",
    "                                          ('times', [person[5]])])\n",
    "        with open(db_file, 'a') as fd:\n",
    "            df.to_csv(fd, index=False, header=False)\n",
    "\n",
    "    def getAnalysisData(self, recog_results, identity_real, ie):\n",
    "        i_post = ie.posterior(self.I)[:]\n",
    "        i_max_cpt = np.max(ie.posterior(self.I)[:])\n",
    "        identity_est = self.i_labels[np.argmax(ie.posterior(self.I)[:])]\n",
    "        isclose_ar = np.isclose(i_post, i_max_cpt)\n",
    "        if np.isclose(i_post, i_max_cpt).all():\n",
    "            # if all states are equally likely then the person is unknown\n",
    "            identity_est = \"unknown-equal\"\n",
    "        elif len(isclose_ar[isclose_ar==True]) > 1:\n",
    "            # if maximum appears more than one time in the array\n",
    "            identity_est = \"unknown-max-equal\"\n",
    "        elif i_max_cpt < self.conf_min_identity:\n",
    "             # if maximum confidence is lower than self.conf_min_identity \n",
    "            identity_est = \"unknown-low\"\n",
    "        date_today = recog_results[4][2] + \" \" + recog_results[4][3] + \" \" + recog_results[4][4] + \" \" + recog_results[4][0]\n",
    "        date_now = str(datetime.strptime(date_today, '%d %B %Y %H:%M:%S'))\n",
    "        data = OrderedDict([(\"Date\", date_now),\n",
    "                (\"Database\", self.i_labels),\n",
    "                (\"I_real\", identity_real),\n",
    "                (\"I_est\", [identity_est, i_max_cpt]),\n",
    "                (\"I_cpt\", self.r_bn.cpt(self.I)[:].tolist()),\n",
    "                (\"I_posterior\", ie.posterior(self.I)[:].tolist()),\n",
    "                (\"F_est\", recog_results[0]),\n",
    "                (\"F_cpt\", self.r_bn.cpt(self.F)[:].tolist()),\n",
    "                (\"F_posterior\", ie.posterior(self.F)[:].tolist()),\n",
    "                (\"G_est\", recog_results[1]),\n",
    "                (\"G_cpt\", self.r_bn.cpt(self.G)[:].tolist()),\n",
    "                (\"G_posterior\", ie.posterior(self.G)[:].tolist()),\n",
    "                (\"A_est\", recog_results[2]),\n",
    "                (\"A_cpt\", self.r_bn.cpt(self.A)[:].tolist()),\n",
    "                (\"A_posterior\", ie.posterior(self.A)[:].tolist()),\n",
    "                (\"H_est\", recog_results[3]),\n",
    "                (\"H_cpt\", self.r_bn.cpt(self.H)[:].tolist()),\n",
    "                (\"H_posterior\", ie.posterior(self.H)[:].tolist()),\n",
    "                (\"T_est\", recog_results[4]),\n",
    "                (\"T_cpt\", self.r_bn.cpt(self.T)[:].tolist()),\n",
    "                (\"T_posterior\", ie.posterior(self.T)[:].tolist())])\n",
    "        return data\n",
    "    \n",
    "    def saveAnalysisToDB(self, recog_results, identity_real, ie):\n",
    "        \"\"\"Call this file for self.num_people >= 2\"\"\"\n",
    "        data = self.getAnalysisData(recog_results, identity_real, ie)\n",
    "        \n",
    "        db_handler = db.DbHandler()\n",
    "        db_handler.save_recognition_data(data)\n",
    "    \n",
    "    def saveAnalysisToJson(self, recog_results, identity_real, ie, isPrevSavedToAnalysis, num_recog = None):\n",
    "        \"\"\"Call this file for self.num_people >= 2\"\"\"\n",
    "                \n",
    "        a = []\n",
    "        if self.isMultipleRecognitions and num_recog < self.num_mult_recognitions - 1:\n",
    "            self.analysis_data_list.append(self.getAnalysisData(recog_results, identity_real, ie))\n",
    "        else:\n",
    "            if self.isMultipleRecognitions:\n",
    "                self.analysis_data_list.append(self.getAnalysisData(recog_results, identity_real, ie))\n",
    "                a = self.analysis_data_list\n",
    "                if self.num_recognitions > 0:\n",
    "                    num_file = self.num_recognitions - self.num_mult_recognitions + 1\n",
    "                else:\n",
    "                    num_file = self.num_recognitions\n",
    "            else:\n",
    "                a.append(self.getAnalysisData(recog_results, identity_real, ie))\n",
    "                num_file = self.num_recognitions\n",
    "                \n",
    "            if isPrevSavedToAnalysis:\n",
    "                fname = self.analysis_file.replace(\".json\",\"\") + str(num_file) + \"_2.json\"\n",
    "            else:\n",
    "                fname = self.analysis_file.replace(\".json\",\"\") + str(num_file) + \".json\"\n",
    "    #         if not os.path.isfile(fname):\n",
    "            with open(fname, mode='w') as f:\n",
    "                f.write(json.dumps(a, ensure_ascii=False, indent=2))\n",
    "    #         else:\n",
    "    #             with open(fname) as feedsjson:\n",
    "    #                 feeds = json.load(feedsjson, object_pairs_hook=OrderedDict)\n",
    "\n",
    "    #             feeds.append(data)\n",
    "    #             with open(fname, mode='w') as f:\n",
    "    #                 f.write(json.dumps(feeds, ensure_ascii=False, indent=2))\n",
    "            \n",
    "    def updateNodes(self, p_id):\n",
    "        \"\"\"Call the function when a new person added is to the db\n",
    "        CPT is a property of the BN and not the variable, therefore, \n",
    "        to add a new state to a node, it is necessary to copy the previous CPT,\n",
    "        change it accordingly (normalize it, or change it?), \n",
    "        erase the node, redefine the node \n",
    "        (e.g. self.face = gum.LabelizedVariable(\"F\",\"Face\",num_people)), \n",
    "        add the changed node back to the BN, add the arcs, and add the changed CPT to it\n",
    "        change the CPT of the child nodes\n",
    "        \"\"\"\n",
    "        # Update the face recognition rate depending on the function of change depending on the number of people in the db\n",
    "        prev_face_recog_rate = self.face_recognition_rate\n",
    "        self.updateFaceRecognitionRate()\n",
    "        \n",
    "        # Copy CPTs\n",
    "        cpts = []\n",
    "        for counter in range(0,self.r_bn.size()):\n",
    "            nod = self.r_bn.idFromName(self.node_names[counter])\n",
    "            cpts.append(self.r_bn.cpt(nod)[:])\n",
    "        \n",
    "        # Erase I and F\n",
    "        self.r_bn.erase(self.I)\n",
    "        self.r_bn.erase(self.F)\n",
    "        \n",
    "        # Change and add nodes\n",
    "        # Face node\n",
    "        self.face = gum.LabelizedVariable(\"F\",\"Face\",0)\n",
    "        print \"self.i_labels:\" + str(self.i_labels)\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            self.face.addLabel(self.i_labels[counter]) \n",
    "        self.F = self.r_bn.add(self.face)\n",
    "        \n",
    "        # Identity node\n",
    "        self.identity = gum.LabelizedVariable(\"I\",\"Identity\",0)\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            self.identity.addLabel(self.i_labels[counter])       \n",
    "        self.I = self.r_bn.add(self.identity)        \n",
    "    \n",
    "        self.addArcs()\n",
    "\n",
    "        # Change CPT\n",
    "        updated_cpt_I = []\n",
    "        for counter in range(0, len(self.i_labels)):\n",
    "            if counter < len(self.i_labels) - 1:      \n",
    "#                 updated_cpt_F = np.append(cpts[1][counter], [self.init_min_threshold])\n",
    "                if self.num_occurrences[counter] == 0:\n",
    "                    for ff in range(0, len(self.i_labels)-1):\n",
    "                        if np.isclose(cpts[1][counter][ff], (1-prev_face_recog_rate)/(len(self.i_labels)-2)):\n",
    "                            cpts[1][counter][ff] = (1-self.face_recognition_rate)/(len(self.i_labels)-1)\n",
    "                    updated_cpt_F = cpts[1][counter][:]\n",
    "                else:\n",
    "                    occur = self.num_occurrences[counter] + 1\n",
    "                    updated_cpt_F = [i*occur for i in cpts[1][counter]]\n",
    "                updated_cpt_F = np.append(updated_cpt_F, [(1-self.face_recognition_rate)/(len(self.i_labels)-1)]) \n",
    "                updated_cpt_F = self.normalise(updated_cpt_F)\n",
    "                self.r_bn.cpt(self.F)[{'I':self.i_labels[counter]}] = updated_cpt_F[:]\n",
    "                \n",
    "                self.r_bn.cpt(self.G)[{'I':self.i_labels[counter]}] = cpts[2][counter][:]\n",
    "                self.r_bn.cpt(self.A)[{'I':self.i_labels[counter]}] = cpts[3][counter][:]\n",
    "                self.r_bn.cpt(self.H)[{'I':self.i_labels[counter]}] = cpts[4][counter][:]\n",
    "                self.r_bn.cpt(self.T)[{'I':self.i_labels[counter]}] = cpts[5][counter][:]\n",
    "            else:\n",
    "                self.addLikelihoods(counter)\n",
    "                \n",
    "        self.r_bn.cpt(self.I)[:] = self.updatePriorI(p_id)\n",
    "        \n",
    "        ie = gum.LazyPropagation(self.r_bn)\n",
    "        ie.makeInference()\n",
    "        \n",
    "#     def addPersonToBN(self, person, isDBinCSV = False):\n",
    "    def addPersonToBN(self, person):\n",
    "        \"\"\"get from input (for adding people into db) (person = [\"1\", Jane\", \"Female\", 26, 175, [arrayOfTimesOfSessionsInDateTimeFormat]])\"\"\"\n",
    "        if not self.isBNLoaded:            \n",
    "            self.loadBN(self.recog_file, self.csv_file, self.initial_recognition_file)\n",
    "#         person[0] = person[0].replace(\" \",\"_\")\n",
    "        if person[0] in self.i_labels:\n",
    "            logging.debug(\"The patient is already in the database.\")\n",
    "        else:\n",
    "            self.updateData(person)\n",
    "            if self.isDBinCSV:\n",
    "                self.saveDBToCSV(self.db_file, person)\n",
    "                \n",
    "        if self.num_people == 2:\n",
    "            self.r_bn=gum.BayesNet('RecogniserBN')\n",
    "            self.addNodes()\n",
    "            self.addArcs()\n",
    "            self.setNumOccurrences(self.csv_file)\n",
    "            self.addCpts(self.csv_file, self.initial_recognition_file)\n",
    "        elif self.num_people > 2:\n",
    "            if self.r_bn.variableFromName(\"I\").toLabelizedVar().isLabel(person[0]):\n",
    "                logging.debug(\"The patient is already in the network.\")\n",
    "            else:\n",
    "                self.updateNodes(person[0])\n",
    "                self.num_occurrences.append(0)\n",
    "    \n",
    "    def saveImageToTablet(self, p_id, num_recog=None):\n",
    "        # TODO: check with windows (/ might need to be \\ instead)\n",
    "        if self.isMemoryOnRobot:\n",
    "            temp_image = self.imagePath\n",
    "            image_dir = \"/home/nao/dev/images/\"\n",
    "        else:\n",
    "            cur_dir = os.path.dirname(os.path.realpath(__file__))\n",
    "            temp_dir = os.path.abspath(os.path.join(cur_dir, '../..', 'cam')) + \"/\"\n",
    "            image_dir = os.path.abspath(os.path.join(cur_dir, '', 'images')) + \"/\"\n",
    "            temp_image = temp_dir + \"temp.jpg\"\n",
    "\n",
    "        if self.isMultipleRecognitions:\n",
    "            match_name = image_dir + p_id + \"*-0.jpg\"\n",
    "            num_matches = len(glob.glob(match_name)) + 1\n",
    "            orig_matches = num_matches\n",
    "            to_rep = str(num_recog) + \".jpg\"\n",
    "            temp_image = self.imagePath.replace(\".jpg\", to_rep)\n",
    "            counter = 0 \n",
    "            for i in range(0,4):\n",
    "                if num_matches/10 != 0:\n",
    "                    num_matches = num_matches/10\n",
    "                    counter += 1 \n",
    "                else:\n",
    "                    counter += 1 \n",
    "                    break\n",
    "            save_name = image_dir + p_id + \"_\" + (str(0)*(4-counter)) + str(orig_matches) + \"-\" + str(num_recog) +\".jpg\" \n",
    "            os.rename(temp_image,save_name)\n",
    "        else:\n",
    "            match_name = image_dir + p_id + \"*.jpg\"\n",
    "            num_matches = len(glob.glob(match_name)) + 1\n",
    "            orig_matches = num_matches\n",
    "            counter = 0 \n",
    "            for i in range(0,4):\n",
    "                if num_matches/10 != 0:\n",
    "                    num_matches = num_matches/10\n",
    "                    counter += 1 \n",
    "                else:\n",
    "                    counter += 1 \n",
    "                    break\n",
    "            save_name = image_dir + p_id + \"_\" + (str(0)*(4-counter)) + str(orig_matches) + \".jpg\"     \n",
    "            os.rename(temp_image,save_name)\n",
    "    \n",
    "    def setPersonIdentityMult(self, isRegistered = True, p_id = None, recog_results_from_file = None):\n",
    "        isPrevSavedToAnalysis = False\n",
    "        if p_id is None:\n",
    "            p_id = self.identity_est\n",
    "        if self.isAlreadyRegistered(p_id):\n",
    "            self.patientAlreadyRegistered = True\n",
    "            if not isRegistered:\n",
    "                logging.debug(\"The patient is already registered.\")\n",
    "        else:\n",
    "            self.patientAlreadyRegistered = False\n",
    "            if isRegistered:\n",
    "                isRegistered = False\n",
    "                self.isRegistered = False\n",
    "        if not isRegistered:\n",
    "            if self.patientAlreadyRegistered:\n",
    "                self.learnPerson(self.patientAlreadyRegistered, p_id)\n",
    "            else:\n",
    "                if self.num_people > 1:\n",
    "                    for num_recog in range(0, self.num_mult_recognitions):\n",
    "                        self.nonweighted_evidence = self.mult_recognitions_list[num_recog]\n",
    "                        self.updateProbabilities(self.unknown_var, self.ie_list[num_recog])\n",
    "                self.learnPerson(self.patientAlreadyRegistered, p_id)\n",
    "\n",
    "            if self.num_people > 1:\n",
    "                start_time = time.time()\n",
    "                self.analysis_data_list = []\n",
    "                for num_recog in range(0, self.num_mult_recognitions):\n",
    "#                     self.saveAnalysisToDB(self.recog_results_list[num_recog], p_id, self.ie_list[num_recog])\n",
    "                    self.saveAnalysisToJson(self.recog_results_list[num_recog], p_id, self.ie_list[num_recog], isPrevSavedToAnalysis, num_recog = num_recog)\n",
    "                isPrevSavedToAnalysis = True\n",
    "                print \"save analysis to db time: \" + str(time.time() - start_time)\n",
    "            if self.isAddPersonToDB:\n",
    "                self.addPersonToBN(self.personToAdd)\n",
    "            self.mult_recognitions_list = []\n",
    "            self.recog_results_list = []    \n",
    "            # multi-threading\n",
    "            for num_recog in range(0, self.num_mult_recognitions):\n",
    "                self.recog_results = self.recognisePerson(num_recog)\n",
    "                self.recog_results_list.append(self.recog_results) \n",
    "                self.mult_recognitions_list.append(self.fillNonweightedEvidence(self.recog_results))\n",
    "             #end of multi-threading\n",
    "        else:\n",
    "             self.learnPerson(isRegistered, p_id)\n",
    "        if self.num_people < 2:\n",
    "            for num_recog in range(0, self.num_mult_recognitions):\n",
    "                self.nonweighted_evidence = self.mult_recognitions_list[num_recog]\n",
    "                self.saveCSV(self.csv_file, p_id)\n",
    "        else:\n",
    "            if not isRegistered:\n",
    "                # get the inference from the final recognition\n",
    "                self.ie_list = []\n",
    "                # multi-threading\n",
    "                for num_recog in range(0, self.num_mult_recognitions):\n",
    "                    self.ie = self.setEvidence(self.recog_results_list[num_recog])\n",
    "                    # TODO: check if I can update likelihoods using posteriors for I = p_id using setEvidence({\"I\":p_id})!!!\n",
    "#                     print \"before setting identity real posteriors\"\n",
    "#                     self.printInference(self.ie)\n",
    "\n",
    "#                     self.ie.setEvidence({\"I\":p_id})\n",
    "#                     self.ie.makeInference()\n",
    "\n",
    "#                     print \"after setting identity real posteriors\"\n",
    "#                     self.printInference(self.ie)\n",
    "                    self.ie_list.append(self.ie)\n",
    "                #end of multi-threading\n",
    "            self.analysis_data_list = []\n",
    "            for num_recog in range(0, self.num_mult_recognitions):\n",
    "                self.nonweighted_evidence = self.mult_recognitions_list[num_recog]\n",
    "                self.recog_results = self.recog_results_list[num_recog]\n",
    "                self.ie = self.ie_list[num_recog]\n",
    "                \n",
    "                # multi-threading to save independently (thread1: savecsv and thread 2: savebn and saveanalysistodb/json)\n",
    "                self.saveCSV(self.csv_file, p_id)\n",
    "                self.saveBN(self.recog_file, p_id, self.ie, num_recog)\n",
    "#                 self.saveAnalysisToDB(self.recog_results, p_id, self.ie)\n",
    "                self.saveAnalysisToJson(self.recog_results, p_id, self.ie, isPrevSavedToAnalysis, num_recog = num_recog)\n",
    "                # end of multi-threading to save independently\n",
    "        \n",
    "        return self.names[self.i_labels.index(p_id)]\n",
    "#         return p_id\n",
    "\n",
    "    def setPersonToAdd(self, personToAdd):\n",
    "        self.isAddPersonToDB = True\n",
    "        self.personToAdd = personToAdd \n",
    "        \n",
    "    def setPersonIdentity(self, isRegistered = True, p_id = None, recog_results_from_file = None):\n",
    "        self.recog_results_from_file = recog_results_from_file\n",
    "        if self.isMultipleRecognitions:\n",
    "            return self.setPersonIdentityMult(isRegistered, p_id, recog_results_from_file)\n",
    "        \n",
    "        isPrevSavedToAnalysis = False\n",
    "        if p_id is None:\n",
    "            p_id = self.identity_est\n",
    "        if self.isAlreadyRegistered(p_id):\n",
    "            self.patientAlreadyRegistered = True\n",
    "            if not isRegistered:\n",
    "                logging.debug(\"The patient is already registered.\")\n",
    "        else:\n",
    "            self.patientAlreadyRegistered = False\n",
    "            if isRegistered:\n",
    "                isRegistered = False\n",
    "                self.isRegistered = False\n",
    "        if not isRegistered:\n",
    "            if self.patientAlreadyRegistered:\n",
    "                self.learnPerson(self.patientAlreadyRegistered, p_id)\n",
    "            else:\n",
    "                if self.num_people > 1:\n",
    "                    self.updateProbabilities(self.unknown_var, self.ie)\n",
    "                self.learnPerson(self.patientAlreadyRegistered, p_id)\n",
    "\n",
    "            if self.num_people > 1:\n",
    "                start_time = time.time()\n",
    "#                 self.saveAnalysisToDB(self.recog_results, p_id, self.ie)\n",
    "                self.saveAnalysisToJson(self.recog_results, p_id, self.ie, isPrevSavedToAnalysis)\n",
    "                isPrevSavedToAnalysis = True\n",
    "                print \"save analysis to db time: \" + str(time.time() - start_time)\n",
    "            if self.isAddPersonToDB:\n",
    "                self.addPersonToBN(self.personToAdd)\n",
    "                \n",
    "            self.recog_results = self.recognisePerson()\n",
    "            self.nonweighted_evidence = self.fillNonweightedEvidence(self.recog_results)\n",
    "        else:\n",
    "             self.learnPerson(isRegistered, p_id)\n",
    "        if self.num_people < 2:\n",
    "            self.saveCSV(self.csv_file, p_id)\n",
    "        else:\n",
    "            if not isRegistered:\n",
    "                # get the inference from the final recognition\n",
    "                self.ie = self.setEvidence(self.recog_results)\n",
    "                \n",
    "            # TODO: check if I can update likelihoods using posteriors for I = p_id using setEvidence({\"I\":p_id})!!!\n",
    "#             print \"before setting identity real posteriors\"\n",
    "#             self.printInference(self.ie)\n",
    "            \n",
    "#             self.ie.setEvidence({\"I\":p_id})\n",
    "#             self.ie.makeInference()\n",
    "            \n",
    "#             print \"after setting identity real posteriors\"\n",
    "#             self.printInference(self.ie)\n",
    "            \n",
    "            # multi-threading to save independently (thread1: savecsv and thread 2: savebn and saveanalysistodb/json)\n",
    "            self.saveCSV(self.csv_file, p_id)\n",
    "            self.saveBN(self.recog_file, p_id, self.ie)\n",
    "            start_time = time.time()\n",
    "#             self.saveAnalysisToDB(self.recog_results, p_id, self.ie)\n",
    "            self.saveAnalysisToJson(self.recog_results, p_id, self.ie, isPrevSavedToAnalysis)\n",
    "            print \"save analysis to db time: \" + str(time.time() - start_time)\n",
    "            # end of multi-threading to save independently\n",
    "            \n",
    "        return self.names[self.i_labels.index(p_id)]\n",
    "#         return p_id\n",
    "    \n",
    "    def recognise(self, isRegistered = True, recog_results_from_file = None):\n",
    "        \"\"\"isRegistered = False if register button is pressed\"\"\"\n",
    "        self.recog_results = []\n",
    "        self.recog_results_from_file = recog_results_from_file\n",
    "        if not self.isBNLoaded:\n",
    "            self.loadBN(self.recog_file, self.csv_file, self.initial_recognition_file)\n",
    "        \n",
    "        if self.isMultipleRecognitions:\n",
    "            self.mult_recognitions_list = []\n",
    "            self.recog_results_list = []\n",
    "            self.ie_list = []\n",
    "            # multi-threading\n",
    "            for num_recog in range(0, self.num_mult_recognitions):\n",
    "                self.recog_results = self.recognisePerson(num_recog)\n",
    "                self.mult_recognitions_list.append(self.fillNonweightedEvidence(self.recog_results))\n",
    "                self.recog_results_list.append(self.recog_results)\n",
    "                if self.num_people > 1:\n",
    "                    self.ie = self.setEvidence(self.recog_results)\n",
    "                    self.ie_list.append(self.ie)\n",
    "                    i_post = np.array(self.ie.posterior(self.I)[:])\n",
    "                    self.identity_est = self.getEstimatedIdentity(i_post)\n",
    "                else:\n",
    "                    self.identity_est = self.getEstimatedIdentity()\n",
    "                self.saveEstimatedResultCSV(self.initial_recognition_file, self.recog_results, self.identity_est)\n",
    "            #end of multi-threading\n",
    "            if self.num_people > 1:\n",
    "                for r in range(0, self.num_mult_recognitions):\n",
    "                    if r== 0:\n",
    "                        ie_avg = self.ie_list[r].posterior(self.I)[:]\n",
    "                    else:\n",
    "                        temp_p = self.ie_list[r].posterior(self.I)[:]\n",
    "                        ie_avg = [x + y for x, y in zip(ie_avg, temp_p)]\n",
    "                self.identity_prob_list = self.normalise(ie_avg)\n",
    "                print \"ie_avg:\" + str(self.identity_prob_list)\n",
    "                self.identity_est = self.getEstimatedIdentity(self.identity_prob_list)\n",
    "        else:\n",
    "            self.recog_results = self.recognisePerson()\n",
    "            print \"self.recog_results\" + str(self.recog_results)\n",
    "            self.nonweighted_evidence = self.fillNonweightedEvidence(self.recog_results)\n",
    "            if self.num_people > 1:\n",
    "                self.ie = self.setEvidence(self.recog_results)\n",
    "                self.identity_prob_list = np.array(self.ie.posterior(self.I)[:])\n",
    "                self.identity_est = self.getEstimatedIdentity(self.identity_prob_list)\n",
    "            else:\n",
    "                self.identity_est = self.getEstimatedIdentity()\n",
    "                self.identity_prob_list = [1.0] # for unknown\n",
    "            self.saveEstimatedResultCSV(self.initial_recognition_file, self.recog_results, self.identity_est)\n",
    "        return self.identity_est\n",
    "    \n",
    "#     def getEstimatedIdentity(self, recog_results, i_post = None):\n",
    "    def getEstimatedIdentity(self, i_post = None):\n",
    "        identity_est = \"\"\n",
    "        self.isUnknownCondition = False\n",
    "        if self.num_people > 1:\n",
    "            i_max_cpt = np.max(i_post)\n",
    "            identity_est = self.i_labels[np.argmax(i_post)]\n",
    "            isclose_ar = np.isclose(i_post, i_max_cpt)\n",
    "            if i_max_cpt < self.conf_min_identity or len(isclose_ar[isclose_ar==True]) > 1:                 \n",
    "                print \"unknown condition\"\n",
    "                self.isUnknownCondition = True\n",
    "                # if all states are equally likely or if maximum confidence is lower than self.conf_min_identity then person is unknown\n",
    "                identity_est = self.unknown_var   \n",
    "        else:\n",
    "#             if recog_results[0][1]:\n",
    "#                 if recog_results[0][1][0][1] > self.conf_min_identity:\n",
    "#                     identity_est = recog_results[0][1][0][0]\n",
    "            identity_est = self.unknown_var\n",
    "#             if identity_est == \"\":\n",
    "#                 identity_est = self.unknown_var\n",
    "        identity_est = str(identity_est)\n",
    "        return identity_est\n",
    "\n",
    "    def initSession(self, isRegistered = True, isMemoryRobot = True, isAddPersonToDB = False, isDBinCSV = False, personToAdd = []):\n",
    "        self.start_recog_time = time.time()\n",
    "        self.isRegistered = isRegistered\n",
    "        self.isMemoryRobot = isMemoryRobot\n",
    "        self.isAddPersonToDB = isAddPersonToDB\n",
    "        self.isDBinCSV = isDBinCSV\n",
    "        self.personToAdd = personToAdd\n",
    "        \n",
    "        self.df_I = []\n",
    "        self.loadSentencesForRecognition()\n",
    "        self.isBNLoaded = False\n",
    "        textToSay = self.lookAtTablet\n",
    "        if isMemoryRobot and isRegistered:\n",
    "            textToSay += self.pleasePhrase\n",
    "        else:\n",
    "            textToSay += self.enterName\n",
    "#         self.say(textToSay)\n",
    "#         print textToSay\n",
    "        \n",
    "    def startRecognition(self, recog_results_from_file = None):\n",
    "        \"\"\"call initSession and take picture before calling this function\"\"\"\n",
    "        identity_est = self.recognise(isRegistered = self.isRegistered, recog_results_from_file = recog_results_from_file)\n",
    "        \n",
    "        if self.isMemoryRobot and self.isRegistered:\n",
    "            if identity_est == self.unknown_var:\n",
    "                textToSay = self.unknownPerson\n",
    "            else:\n",
    "                identity_say = self.names[self.i_labels.index(identity_est)].split()\n",
    "#                 identity_say = identity_est.split(\"_\") #TODO: change split character if necessary\n",
    "                textToSay = self.askForIdentityConfirmal.replace(\"XX\", str(identity_say[0]))\n",
    "#             self.say(textToSay)\n",
    "            print textToSay\n",
    "        self.identity_est = identity_est\n",
    "        return identity_est\n",
    "    \n",
    "    def setNumOccurrences(self, csv_file):\n",
    "        self.num_occurrences = [0 for i in range(0, len(self.i_labels))]\n",
    "        df_names_registering = pandas.read_csv(csv_file, usecols=[\"I\", \"R\"], dtype={\"I\": object})\n",
    "        occurrences = df_names_registering.I.value_counts()\n",
    "        num_unknown_occurrences = df_names_registering.R.values.sum()\n",
    "        for val, cnt in occurrences.iteritems():\n",
    "            index_name = self.i_labels.index(val)\n",
    "            self.num_occurrences[index_name] = cnt\n",
    "        self.num_occurrences[self.i_labels.index(self.unknown_var)] = num_unknown_occurrences\n",
    "        \n",
    "    def isAlreadyRegistered(self, p_id):\n",
    "        if not self.df_I:\n",
    "            self.df_I = set(pandas.read_csv(self.csv_file, usecols=[\"I\"], dtype={\"I\": object}).I.tolist())\n",
    "        return p_id in self.df_I\n",
    "\n",
    "    def confirmPersonIdentity(self, p_id = None, recog_results_from_file = None):\n",
    "        \"\"\"call startRecognition before calling this function, and then ask for name from the person\"\"\"\n",
    "        # TODO: add more phrases for the welcome, and I am sorry phrases\n",
    "        name = self.setPersonIdentity(isRegistered = self.isRegistered, p_id = p_id, recog_results_from_file = recog_results_from_file)\n",
    "        if self.isMemoryRobot:\n",
    "            identity_say = name.split() #TODO: change split character if necessary\n",
    "            if p_id is not None:\n",
    "                if self.isRegistered:\n",
    "                    falseRecognitionSentence = random.choice(self.falseRecognition)\n",
    "                    textToSay = falseRecognitionSentence.replace(\"XX\", str(identity_say[0]))\n",
    "                else:\n",
    "                    if self.patientAlreadyRegistered:\n",
    "                        textToSay = self.falseRegistration.replace(\"XX\", str(identity_say[0]))\n",
    "                    else:\n",
    "                        textToSay = self.registrationPhrase.replace(\"XX\", str(identity_say[0]))\n",
    "            else:\n",
    "                correctRecognition = random.choice(self.correctRecognition)\n",
    "                textToSay = correctRecognition.replace(\"XX\", str(identity_say[0]))\n",
    "                \n",
    "#             self.say(textToSay)\n",
    "            print textToSay\n",
    "        calc_time = time.time() - self.start_recog_time\n",
    "        if p_id is None:\n",
    "            identity_real = self.identity_est\n",
    "        else:\n",
    "            identity_real = p_id\n",
    "        self.saveComparisonCSV(self.comparison_file, identity_real, self.identity_est, self.identity_prob_list, calc_time)\n",
    "\n",
    "    def loadSentencesForRecognition(self):\n",
    "        # TODO: Change enter name to choose name (in Spanish as well)\n",
    "        if self.useSpanish:\n",
    "            self.lookAtTablet = \"Hola, podrias mirar la pantalla \"\n",
    "            self.pleasePhrase = \"por favor?\"\n",
    "            self.enterName = \"e ingresar tu nombre por favor?\"\n",
    "            self.unknownPerson = \"Oh lo siento mucho, No pude reconocer quien eres! Podrias ingresar tu nombre en la pantalla por favor?\"\n",
    "            self.askForIdentityConfirmal = \"Hola XX, es bueno verte de nuevo ! Podrias confirmar que eres tu?\"   \n",
    "            self.falseRecognition = [\"Ah, por supuesto, me disculpo! Parece que mis ojos me estan fallando... Bienvenido de nuevo XX!\", \"Te ves diferente hoy, es un nuevo corte?\"]\n",
    "            self.registrationPhrase = \"Hola XX, encantado de conocerte\"\n",
    "            self.falseRegistration = \"Ya te había visto antes! Es un gusto verte de nuevo XX!\"\n",
    "            self.correctRecognition = [\"Sabia que eras tu, solo queria estar seguro\", \"Te ves bien hoy XX!\"]\n",
    "        else:\n",
    "            self.lookAtTablet = \"Hello there, could you look at the tablet \"\n",
    "            self.pleasePhrase = \"please?\"\n",
    "            self.enterName = \"and enter your id please?\"\n",
    "            self.unknownPerson = \"Oh I'm sorry, I couldn't recognise who you are! Could you enter your id on the tablet please?\"\n",
    "            self.askForIdentityConfirmal = \"Hello XX, it is nice to see you again! Could you confirm that it is you please?\"   \n",
    "            self.falseRecognition = [\"Ah, of course, my apologies! My eyes seem to fail me.. Welcome back XX!\", \"You look different today XX, is it a new haircut?\"]\n",
    "            self.registrationPhrase = \"Hello XX, nice to meet you!\"\n",
    "            self.falseRegistration = \"But we have met before! Nice to see you again XX!\"\n",
    "            self.correctRecognition = [\"I knew it was you, just wanted to be sure!\", \"You look very good today XX!\"]\n",
    "            \n",
    "    def say(self, sentence):\n",
    "        self.tts.setVolume(0.85)\n",
    "        self.tts.setParameter(\"speed\", 80)\n",
    "        threading.Thread(target = self.animatedSpeechProxy.say, args=(sentence,self.configuration)).start()\n",
    "\n",
    "    def resetFiles(self):\n",
    "        if os.path.isfile(self.recog_file):\n",
    "            os.remove(self.recog_file)\n",
    "        if os.path.isfile(self.csv_file):\n",
    "            os.remove(self.csv_file)\n",
    "        with open(self.csv_file, 'wb') as outcsv:\n",
    "            writer = csv.writer(outcsv)\n",
    "            writer.writerow([\"I\", \"F\", \"G\", \"A\", \"H\", \"T\", \"R\"])\n",
    "        if os.path.isfile(self.initial_recognition_file):\n",
    "            os.remove(self.initial_recognition_file)\n",
    "        with open(self.initial_recognition_file, 'wb') as outcsv:\n",
    "            writer = csv.writer(outcsv)\n",
    "            writer.writerow([\"I_est\", \"F\", \"G\", \"A\", \"H\", \"T\"])\n",
    "#         if os.path.isfile(self.db_file):\n",
    "#             os.remove(self.db_file)\n",
    "#         with open(self.db_file, 'wb') as outcsv:\n",
    "#             writer = csv.writer(outcsv)\n",
    "#             writer.writerow([\"id\", \"name\", \"gender\", \"age\", \"height\", \"times\"])\n",
    "        analysis_dir = self.analysis_file.replace(\"/Analysis.json\",\"\")\n",
    "        if os.path.isdir(analysis_dir):\n",
    "            shutil.rmtree(analysis_dir)\n",
    "        os.makedirs(analysis_dir)\n",
    "        with open(self.comparison_file, 'wb') as outcsv:\n",
    "            writer = csv.writer(outcsv)\n",
    "            writer.writerow([\"I_real\", \"I_est\", \"I_prob\", \"Calc_time\", \"R\"])\n",
    "        \n",
    "    \"\"\"Print functions:\"\"\"\n",
    "    def printPriors(self):\n",
    "        print \"priors:\"\n",
    "        print \"I:\"\n",
    "        print self.r_bn.cpt(self.I)[:]\n",
    "        print \"F:\"\n",
    "        print self.r_bn.cpt(self.F)[:]\n",
    "        print \"G:\"\n",
    "        print self.r_bn.cpt(self.G)[:]\n",
    "        print \"A:\"\n",
    "        for counter in range(0,len(self.i_labels)):\n",
    "            plt.plot(range(self.age_min, self.age_max + 1),self.r_bn.cpt(self.A)[{'I':self.i_labels[counter]}], label=self.i_labels[counter])\n",
    "        plt.show()\n",
    "        print \"H:\"\n",
    "        for counter in range(0,len(self.i_labels)):\n",
    "            plt.plot(range(self.height_min, self.height_max + 1),self.r_bn.cpt(self.H)[{'I':self.i_labels[counter]}], label=self.i_labels[counter])\n",
    "        plt.show()\n",
    "        print \"T:\"\n",
    "        for counter in range(0,len(self.i_labels)):\n",
    "            plt.plot(range(self.time_min, self.time_max + 1),self.r_bn.cpt(self.T)[{'I':self.i_labels[counter]}], label=self.i_labels[counter])\n",
    "        plt.show()\n",
    "    \n",
    "    def printEvidence(self, face_result, gender_result, age_result, height_result, time_result):\n",
    "        print \"face weighted evidence\"\n",
    "        print face_result\n",
    "        \n",
    "        print \"gender weighted evidence\"\n",
    "        print gender_result\n",
    "        \n",
    "        print \"age weighted evidence\"\n",
    "        plt.plot(range(self.age_min, self.age_max+1),age_result)\n",
    "        plt.show() \n",
    "\n",
    "        print \"height weighted evidence\"\n",
    "        plt.plot(range(self.height_min, self.height_max+1),height_result)\n",
    "        plt.show()\n",
    "        \n",
    "        print \"time weighted evidence\"\n",
    "        plt.plot(range(self.time_min, self.time_max+1),time_result)\n",
    "        plt.show()\n",
    "        \n",
    "    def printInference(self, ie):\n",
    "        print \"ie.posterior(self.I):\"\n",
    "        print ie.posterior(self.I)\n",
    "        print \"ie.posterior(self.F):\"\n",
    "        print ie.posterior(self.F)\n",
    "        print \"ie.posterior(self.G):\"\n",
    "        print ie.posterior(self.G)\n",
    "        print \"ie.posterior(self.A):\"\n",
    "        plt.plot(range(self.age_min, self.age_max+1),ie.posterior(self.A)[:])\n",
    "        plt.show()\n",
    "        print \"ie.posterior(self.H):\"\n",
    "        plt.plot(range(self.height_min, self.height_max+1),ie.posterior(self.H)[:])\n",
    "        plt.show()\n",
    "        print \"ie.posterior(self.T):\"\n",
    "        plt.plot(range(self.time_min, self.time_max+1),ie.posterior(self.T)[:])\n",
    "        plt.show()\n",
    "    \n",
    "    def printDB(self):\n",
    "        print \"database:\"\n",
    "        print \"self.i_labels: \" + str(self.i_labels)\n",
    "        print \"self.genders: \"  + str(self.genders)\n",
    "        print \"self.ages: \" + str(self.ages)\n",
    "        print \"self.heights: \" + str(self.heights)\n",
    "        print \"self.times: \" + str(self.times)\n",
    "        print \"self.num_people: \" + str(self.num_people)\n",
    "    \n",
    "    \"\"\"Math functions:\"\"\"\n",
    "    def uniformDistribution(self, min_value, max_value):\n",
    "        uni_value = 1.0/(max_value - min_value + 1)\n",
    "        return [uni_value for x in range(min_value, max_value + 1)]\n",
    "    \n",
    "    def getCurve(self, conf = 1.0, mean = 0.0, stddev = 0.0, min_value = 0, max_value = 0, weight = 1.0):\n",
    "        curve = []\n",
    "        if conf > self.max_threshold:\n",
    "            conf = self.max_threshold # decrease the prob. to get a Gaussian distribution\n",
    "            \n",
    "        if np.isclose(stddev, 0.0) and conf >= self.conf_threshold:\n",
    "            # applicable to age only\n",
    "            stddev = 0.5/self.normppf(conf + (1-conf)/2.0)\n",
    "        \n",
    "        if conf < self.conf_threshold:\n",
    "            # uniform distribution\n",
    "            curve = self.uniformDistribution(min_value, max_value)\n",
    "        else:\n",
    "            # Gaussian distribution         \n",
    "#             norm_curve = norm(loc=observed_height,scale=self.stddev_height )\n",
    "            for j in range(min_value, max_value +1):\n",
    "#                 j_pdf = norm_curve.pdf(j)\n",
    "                j_pdf = self.normpdf(j, mean, stddev)\n",
    "                if j_pdf < self.prob_threshold:\n",
    "                    j_pdf = self.prob_threshold\n",
    "                curve.append(math.pow(j_pdf, weight))\n",
    "#                 curve.append(j_pdf)\n",
    "            curve = self.normalise(curve)\n",
    "        return curve\n",
    "    \n",
    "    def normalise(self, array):\n",
    "        sum_array = sum(array)\n",
    "        return [float(i) / sum_array for i in array]\n",
    "        \n",
    "    def softmax(self, array):\n",
    "        array_exp = [math.exp(i) for i in array]  \n",
    "        sum_array_exp = sum(array_exp)  \n",
    "        return [i / sum_array_exp for i in array_exp]\n",
    "        \n",
    "    def normpdf(self, x, loc=0, scale=1):\n",
    "        \"\"\"x is the value that pdf wants to be read at, loc is the mean, and scale is the stddev\n",
    "        From: https://stackoverflow.com/questions/8669235/alternative-for-scipy-stats-norm-pdf\"\"\"\n",
    "        u = float(x-loc) / abs(scale)\n",
    "        y = np.exp(-u*u/2) / (np.sqrt(2*np.pi) * abs(scale))\n",
    "        return y\n",
    "    \n",
    "    def normppf(self, y0):     \n",
    "        \"\"\"From https://stackoverflow.com/questions/41338539/how-to-calculate-a-normal-distribution-percent-point-function-in-python\"\"\"   \n",
    "        \n",
    "        s2pi = 2.50662827463100050242E0\n",
    "\n",
    "        P0 = [\n",
    "            -5.99633501014107895267E1,\n",
    "            9.80010754185999661536E1,\n",
    "            -5.66762857469070293439E1,\n",
    "            1.39312609387279679503E1,\n",
    "            -1.23916583867381258016E0,\n",
    "        ]\n",
    "        \n",
    "        Q0 = [\n",
    "            1,\n",
    "            1.95448858338141759834E0,\n",
    "            4.67627912898881538453E0,\n",
    "            8.63602421390890590575E1,\n",
    "            -2.25462687854119370527E2,\n",
    "            2.00260212380060660359E2,\n",
    "            -8.20372256168333339912E1,\n",
    "            1.59056225126211695515E1,\n",
    "            -1.18331621121330003142E0,\n",
    "        ]\n",
    "        \n",
    "        P1 = [\n",
    "            4.05544892305962419923E0,\n",
    "            3.15251094599893866154E1,\n",
    "            5.71628192246421288162E1,\n",
    "            4.40805073893200834700E1,\n",
    "            1.46849561928858024014E1,\n",
    "            2.18663306850790267539E0,\n",
    "            -1.40256079171354495875E-1,\n",
    "            -3.50424626827848203418E-2,\n",
    "            -8.57456785154685413611E-4,\n",
    "        ]\n",
    "        \n",
    "        Q1 = [\n",
    "            1,\n",
    "            1.57799883256466749731E1,\n",
    "            4.53907635128879210584E1,\n",
    "            4.13172038254672030440E1,\n",
    "            1.50425385692907503408E1,\n",
    "            2.50464946208309415979E0,\n",
    "            -1.42182922854787788574E-1,\n",
    "            -3.80806407691578277194E-2,\n",
    "            -9.33259480895457427372E-4,\n",
    "        ]\n",
    "        \n",
    "        P2 = [\n",
    "            3.23774891776946035970E0,\n",
    "            6.91522889068984211695E0,\n",
    "            3.93881025292474443415E0,\n",
    "            1.33303460815807542389E0,\n",
    "            2.01485389549179081538E-1,\n",
    "            1.23716634817820021358E-2,\n",
    "            3.01581553508235416007E-4,\n",
    "            2.65806974686737550832E-6,\n",
    "            6.23974539184983293730E-9,\n",
    "        ]\n",
    "        \n",
    "        Q2 = [\n",
    "            1,\n",
    "            6.02427039364742014255E0,\n",
    "            3.67983563856160859403E0,\n",
    "            1.37702099489081330271E0,\n",
    "            2.16236993594496635890E-1,\n",
    "            1.34204006088543189037E-2,\n",
    "            3.28014464682127739104E-4,\n",
    "            2.89247864745380683936E-6,\n",
    "            6.79019408009981274425E-9,\n",
    "        ]\n",
    "        if y0 <= 0 or y0 >= 1:\n",
    "            raise ValueError(\"ndtri(x) needs 0 < x < 1\")\n",
    "        negate = True\n",
    "        y = y0\n",
    "        if y > 1.0 - 0.13533528323661269189:\n",
    "            y = 1.0 - y\n",
    "            negate = False\n",
    "    \n",
    "        if y > 0.13533528323661269189:\n",
    "            y = y - 0.5\n",
    "            y2 = y * y\n",
    "            x = y + y * (y2 * self.polevl(y2, P0) / self.polevl(y2, Q0))\n",
    "            x = x * s2pi\n",
    "            return x\n",
    "    \n",
    "        x = math.sqrt(-2.0 * math.log(y))\n",
    "        x0 = x - math.log(x) / x\n",
    "    \n",
    "        z = 1.0 / x\n",
    "        if x < 8.0:\n",
    "            x1 = z * self.polevl(z, P1) / self.polevl(z, Q1)\n",
    "        else:\n",
    "            x1 = z * self.polevl(z, P2) / self.polevl(z, Q2)\n",
    "        x = x0 - x1\n",
    "        if negate:\n",
    "            x = -x\n",
    "    \n",
    "        return x\n",
    "\n",
    "    def polevl(self, x, coef):\n",
    "        accum = 0\n",
    "        for c in coef:\n",
    "            accum = x * accum + c\n",
    "        return accum\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    start_time = time.time()\n",
    "    isSpanish = False\n",
    "    isMultRecognitions = False\n",
    "    num_mult_recognitions = 3\n",
    "    RB = RecogniserBN()\n",
    "    weights = [1.0, 1.0, 1.0, 0.15, 0.22]\n",
    "    RB.setWeights(weights[0], weights[1], weights[2], weights[3], weights[4])\n",
    "    \n",
    "#     RB.connectToRobot(\"192.168.1.105\", useSpanish=isSpanish)\n",
    "    \n",
    "    recog_folder = \"TestCases/TestCase4/\"\n",
    "    RB.setFilePaths(recog_folder)\n",
    "    \n",
    "    RB.resetFiles()\n",
    "    \n",
    "    recog_file = recog_folder + \"recognitions.csv\"\n",
    "    \n",
    "    db_file = recog_folder + \"db_to_learn.csv\"\n",
    "     \n",
    "    df = pandas.read_csv(recog_file, dtype={\"I\": object}, converters={\"F\": ast.literal_eval, \"G\": ast.literal_eval, \"A\": ast.literal_eval, \"H\": ast.literal_eval, \"T\": ast.literal_eval})\n",
    "    recogs_list = df.values.tolist()\n",
    "    \n",
    "    if os.path.isfile(db_file):\n",
    "        df_db = pandas.read_csv(db_file, dtype={\"id\": object}, converters={\"times\": ast.literal_eval})\n",
    "        db_list = df_db.values.tolist()\n",
    "    \n",
    "    print \"loaded test material time: \" + str(time.time() - start_time)\n",
    "    count_recogs = 0\n",
    "    while count_recogs < len(recogs_list):\n",
    "        start_loop = time.time()\n",
    "        recog_results = []\n",
    "        print \"p_id: \" + str(recogs_list[count_recogs][0])\n",
    "        isMemoryRobot = True # True if the robot with memory is used (get this from the days maybe?)\n",
    "        isRegistered =  not recogs_list[count_recogs][6]# False if register button is pressed (i.e. if the person starts the session for the first time)\n",
    "        isAddPersonToDB = recogs_list[count_recogs][6] # True ONLY IF THE EXPERIMENTS ARE ALREADY STARTED, THE BN IS ALREADY CREATED, ONE NEW PERSON IS BEING ADDED!FOR ADDING MULTIPLE PEOPLE AT THE SAME TIME, DELETE RecogniserBN.bif FILE INSTEAD!!!\n",
    "        isDBinCSV = True\n",
    "        person = []\n",
    "        real_identity = recogs_list[count_recogs][0]\n",
    "        if isAddPersonToDB:\n",
    "            if not os.path.isfile(db_file):\n",
    "                warn_msg = db_file + \" should exist if a person is to be added to the db (i.e. if isAddPersonToDB is true).\"\n",
    "                logging.debug(warn_msg)\n",
    "                break        \n",
    "            person = [x for x in db_list if x[0] == recogs_list[count_recogs][0]][0]\n",
    "            person[0] = str(person[0])\n",
    "#             RB.addPersonToBN(person, isDBinCSV = isDBinCSV)\n",
    "            isRegistered = False\n",
    "            \n",
    "        # Press either register button (isRegistered = False) or start session button (isRegistered = True)\n",
    "        RB.initSession(isRegistered = isRegistered, isMemoryRobot = isMemoryRobot, isAddPersonToDB = isAddPersonToDB, isDBinCSV = isDBinCSV, personToAdd = person)\n",
    "        # TODO: take a picture and send to robot!\n",
    "        if isMultRecognitions:\n",
    "            for num_recog in range(0, num_mult_recognitions):\n",
    "                recog_results.append(recogs_list[count_recogs][1:6])\n",
    "                if num_recog < num_mult_recognitions - 1:\n",
    "                    count_recogs += 1\n",
    "        else:\n",
    "            recog_results = recogs_list[count_recogs][1:6]\n",
    "        identity_est = RB.startRecognition(recog_results) # get the estimated identity from the recognition network\n",
    "        \n",
    "        print identity_est\n",
    "        p_id = None\n",
    "        isRecognitionCorrect = False\n",
    "        if isMemoryRobot:\n",
    "            if isRegistered:\n",
    "                if identity_est != \"unknown\":\n",
    "                    # TODO: ask for confirmation of identity_est on the tablet (isRecognitionCorrect = True if confirmed) \n",
    "                    if identity_est == real_identity:\n",
    "                        isRecognitionCorrect = True # True if the name is confirmed by the patient\n",
    "        \n",
    "        if isRecognitionCorrect:\n",
    "            RB.confirmPersonIdentity(recog_results_from_file = recog_results) # save the network, analysis data, csv for learning and picture of the person in the tablet\n",
    "        else:\n",
    "            if isAddPersonToDB:\n",
    "                p_id = person[0]\n",
    "                recog_results = []\n",
    "                count_recogs += 1\n",
    "                if isMultRecognitions:\n",
    "                    for num_recog in range(0, num_mult_recognitions):\n",
    "                        recog_results.append(recogs_list[count_recogs][1:6])\n",
    "                        if num_recog < num_mult_recognitions - 1:\n",
    "                            count_recogs += 1\n",
    "                else:\n",
    "                    recog_results = recogs_list[count_recogs][1:6]\n",
    "            else:\n",
    "                p_id = real_identity # TODO: ask for patient name (p_id) on tablet\n",
    "            RB.confirmPersonIdentity(p_id = p_id, recog_results_from_file = recog_results)\n",
    "                \n",
    "        count_recogs += 1\n",
    "        print \"time of loop: \" + str(time.time() - start_loop)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
